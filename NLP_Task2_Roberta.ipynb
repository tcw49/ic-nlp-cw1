{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "NLP: Task2 Roberta",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2044ba25a1ed45e0a556d3c0b664d3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51f15d05b92d43e089121572e32e1adb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_73665fa8cceb4935b34a9e8be5495823",
              "IPY_MODEL_c6d9b98a720f497f9db7f55ffcef33d2"
            ]
          }
        },
        "51f15d05b92d43e089121572e32e1adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73665fa8cceb4935b34a9e8be5495823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9dd29a5c3d21486bb879f744c0bcd7c7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0540b31a5d134c94848994f248c688b7"
          }
        },
        "c6d9b98a720f497f9db7f55ffcef33d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b00dc42baeb4bb6ab23f92c4d50b180",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 4.01MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a0e0b086939450da7aa66f55c5e4928"
          }
        },
        "9dd29a5c3d21486bb879f744c0bcd7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0540b31a5d134c94848994f248c688b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b00dc42baeb4bb6ab23f92c4d50b180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a0e0b086939450da7aa66f55c5e4928": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40625581f53e4693aff9ecf15d6f5ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_84ef3871a7ff411ba5e1798a2299692a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c94097ffbd694fa48444857a02341727",
              "IPY_MODEL_3aad0e4547fd4ccdbb788f6317f29965"
            ]
          }
        },
        "84ef3871a7ff411ba5e1798a2299692a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c94097ffbd694fa48444857a02341727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8614c1303424112959659c5704e1540",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a782b40102df49f5a945ccbab395c5e8"
          }
        },
        "3aad0e4547fd4ccdbb788f6317f29965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fc027d6431e4bb58668157616b28b22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 4.47MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55e1ccf120794c4c9568da67e2e455ba"
          }
        },
        "f8614c1303424112959659c5704e1540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a782b40102df49f5a945ccbab395c5e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fc027d6431e4bb58668157616b28b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55e1ccf120794c4c9568da67e2e455ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "941e2e44f1cc45d29dcc4ebe14966a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff551ba9390d42dc8d93e99da9bb44e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c162eaed70124bf6b3e5ccbcfc7485c1",
              "IPY_MODEL_1485fe2fe22b46beb81639551fd720b2"
            ]
          }
        },
        "ff551ba9390d42dc8d93e99da9bb44e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c162eaed70124bf6b3e5ccbcfc7485c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bfae6f9baa0a40f38ee921e08f97a4e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc8f890c93d14893ac32113860437ff8"
          }
        },
        "1485fe2fe22b46beb81639551fd720b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0c60c3d7c2584ad98320514a54dfc699",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:12&lt;00:00, 40.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9175a26ad3274ab490b181b8621e5404"
          }
        },
        "bfae6f9baa0a40f38ee921e08f97a4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc8f890c93d14893ac32113860437ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c60c3d7c2584ad98320514a54dfc699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9175a26ad3274ab490b181b8621e5404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f2299fcf59944da840fe2913abd6e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57359d99ca244b5396b0ae297aff7c1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae1f562727f340d181a5eef9fe351789",
              "IPY_MODEL_80ec4d266d714868a82d40cc43d56c8b"
            ]
          }
        },
        "57359d99ca244b5396b0ae297aff7c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae1f562727f340d181a5eef9fe351789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8f4e69cfd9144a5afc1030f7dab9f32",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb00716b40bc4425b178348746d27f28"
          }
        },
        "80ec4d266d714868a82d40cc43d56c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e709c5b1cd99483aae1445732d9a3855",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:09&lt;00:00, 54.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cbc23e8190b4795961c061fe4d37cf8"
          }
        },
        "e8f4e69cfd9144a5afc1030f7dab9f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb00716b40bc4425b178348746d27f28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e709c5b1cd99483aae1445732d9a3855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cbc23e8190b4795961c061fe4d37cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marektopolewski/ic-nlp-cw1/blob/master/NLP_Task2_Roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO114qTM0Blf"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKqe4drh0Blg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6644517-7dde-42e8-a6a2-da05a0c29ff4"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "\n",
        "# !wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip glove.6B.zip\n",
        "# !rm glove.6B.zip\n",
        "\n",
        "!wget -q https://www.cs.rochester.edu/u/nhossain/humicroedit/semeval-2020-task-7-data.zip\n",
        "!unzip -q semeval-2020-task-7-data.zip\n",
        "!rm semeval-2020-task-7-data.zip\n",
        "!rm -r data/task-1/\n",
        "\n",
        "!wget https://www.cs.rochester.edu/u/nhossain/funlines/semeval-2020-task-7-extra-training-data.zip\n",
        "!unzip -q semeval-2020-task-7-extra-training-data.zip\n",
        "!rm semeval-2020-task-7-extra-training-data.zip\n",
        "!mv semeval-2020-task-7-extra-training-data/task-2 data/funlines\n",
        "!rm -r semeval-2020-task-7-extra-training-data\n",
        "\n",
        "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
        "\n",
        "! pip -q install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-24 17:08:41--  https://www.cs.rochester.edu/u/nhossain/funlines/semeval-2020-task-7-extra-training-data.zip\n",
            "Resolving www.cs.rochester.edu (www.cs.rochester.edu)... 192.5.53.208\n",
            "Connecting to www.cs.rochester.edu (www.cs.rochester.edu)|192.5.53.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 431136 (421K) [application/zip]\n",
            "Saving to: ‘semeval-2020-task-7-extra-training-data.zip’\n",
            "\n",
            "\r          semeval-2   0%[                    ]       0  --.-KB/s               \rsemeval-2020-task-7 100%[===================>] 421.03K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2021-02-24 17:08:41 (5.17 MB/s) - ‘semeval-2020-task-7-extra-training-data.zip’ saved [431136/431136]\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 17.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 48.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 52.4MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT-EZhC50Blh"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import torch.optim as optim\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REQlB22W0Blh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90556976-efe0-4b0f-acf0-86db17c9b64e"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR9qzBjJ0Bli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "2044ba25a1ed45e0a556d3c0b664d3f1",
            "51f15d05b92d43e089121572e32e1adb",
            "73665fa8cceb4935b34a9e8be5495823",
            "c6d9b98a720f497f9db7f55ffcef33d2",
            "9dd29a5c3d21486bb879f744c0bcd7c7",
            "0540b31a5d134c94848994f248c688b7",
            "7b00dc42baeb4bb6ab23f92c4d50b180",
            "8a0e0b086939450da7aa66f55c5e4928",
            "40625581f53e4693aff9ecf15d6f5ef7",
            "84ef3871a7ff411ba5e1798a2299692a",
            "c94097ffbd694fa48444857a02341727",
            "3aad0e4547fd4ccdbb788f6317f29965",
            "f8614c1303424112959659c5704e1540",
            "a782b40102df49f5a945ccbab395c5e8",
            "6fc027d6431e4bb58668157616b28b22",
            "55e1ccf120794c4c9568da67e2e455ba",
            "941e2e44f1cc45d29dcc4ebe14966a38",
            "ff551ba9390d42dc8d93e99da9bb44e9",
            "c162eaed70124bf6b3e5ccbcfc7485c1",
            "1485fe2fe22b46beb81639551fd720b2",
            "bfae6f9baa0a40f38ee921e08f97a4e8",
            "bc8f890c93d14893ac32113860437ff8",
            "0c60c3d7c2584ad98320514a54dfc699",
            "9175a26ad3274ab490b181b8621e5404",
            "3f2299fcf59944da840fe2913abd6e46",
            "57359d99ca244b5396b0ae297aff7c1e",
            "ae1f562727f340d181a5eef9fe351789",
            "80ec4d266d714868a82d40cc43d56c8b",
            "e8f4e69cfd9144a5afc1030f7dab9f32",
            "eb00716b40bc4425b178348746d27f28",
            "e709c5b1cd99483aae1445732d9a3855",
            "3cbc23e8190b4795961c061fe4d37cf8"
          ]
        },
        "outputId": "c4b78e8d-85e5-407f-80ea-a0f5017308eb"
      },
      "source": [
        "# Number of epochs\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-05\n",
        "ADAM_EPSILON = 1e-8\n",
        "GRAD_CLIP = 5\n",
        "\n",
        "# Model params\n",
        "context_types = ['none', 'masked', 'original']\n",
        "CONTEXT_TYPE = context_types[2]\n",
        "CLASSIFICATION_HEAD = True\n",
        "\n",
        "# Proportion of training data for train compared to dev\n",
        "TRAINING_RATIO = 0.8\n",
        "AUG_RANDOM_FLIP = True\n",
        "\n",
        "# Pre-trained models\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "transformer = RobertaModel.from_pretrained(\"roberta-base\", output_hidden_states=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2044ba25a1ed45e0a556d3c0b664d3f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40625581f53e4693aff9ecf15d6f5ef7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "941e2e44f1cc45d29dcc4ebe14966a38",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f2299fcf59944da840fe2913abd6e46",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elMRsCQ70Bli"
      },
      "source": [
        "#### Approach 1: Using pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2dEteGGoZd1"
      },
      "source": [
        "def get_span_mask(span, sent_len):\r\n",
        "    bsz = span.shape[0]\r\n",
        "    index_tensor = (\r\n",
        "        torch.tensor(list(range(sent_len)), device=device)\r\n",
        "        .unsqueeze(0)\r\n",
        "        .expand(bsz, sent_len)\r\n",
        "    )\r\n",
        "    start_index, end_index = span.split(1, dim=-1)\r\n",
        "    start_index = start_index + 1\r\n",
        "    end_index = end_index - 1\r\n",
        "\r\n",
        "    start_mask = (index_tensor - start_index) >= 0\r\n",
        "    end_mask = (index_tensor - end_index) <= 0\r\n",
        "    span_mask = start_mask & end_mask\r\n",
        "\r\n",
        "    return span_mask"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVsqpuXCeE-G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4f145a-0848-419a-a88a-243d6d1fbedb"
      },
      "source": [
        "########################################### LOAD DATA ##############################################\r\n",
        "import re\r\n",
        "\r\n",
        "# We create a Dataset so we can create minibatches\r\n",
        "class Task2Dataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self, df):\r\n",
        "      cust_tokenize = lambda x: tokenizer.convert_tokens_to_ids(tokenizer.tokenize(x))\r\n",
        "\r\n",
        "      self.x_edit_1 = [cust_tokenize(x) for x in df.edit_sentence1.tolist()]\r\n",
        "      self.x_masked_1 = [cust_tokenize(x) for x in df.masked1.tolist()]\r\n",
        "      self.y_grade_1 = df.meanGrade1.tolist()\r\n",
        "\r\n",
        "      self.x_edit_2 = [cust_tokenize(x) for x in df.edit_sentence2.tolist()]\r\n",
        "      self.x_masked_2 = [cust_tokenize(x) for x in df.masked2.tolist()]\r\n",
        "      self.y_grade_2 = df.meanGrade2.tolist()\r\n",
        "\r\n",
        "      self.x_original = [cust_tokenize(x) for x in df.original.tolist()]\r\n",
        "      self.y_label = df.label.tolist()\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.y_label)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        flip = np.random.choice([True, False]) if AUG_RANDOM_FLIP else False\r\n",
        "        label = self.y_label[item]\r\n",
        "        return { 'x_edit_1':      getattr(self, f'x_edit_{2 if flip else 1}')[item],\r\n",
        "                 'x_masked_1':    getattr(self, f'x_masked_{2 if flip else 1}')[item],\r\n",
        "                 'y_grade_1':     getattr(self, f'y_grade_{2 if flip else 1}')[item],\r\n",
        "                 'x_edit_2':      getattr(self, f'x_edit_{1 if flip else 2}')[item],\r\n",
        "                 'x_masked_2':    getattr(self, f'x_masked_{1 if flip else 2}')[item],\r\n",
        "                 'y_grade_2':     getattr(self, f'y_grade_{1 if flip else 2}')[item],\r\n",
        "                 'x_original':    self.x_original[item],\r\n",
        "                 'y_label':       3 - label if flip and label != 0 else label }\r\n",
        "\r\n",
        "def preprocess_data(df):\r\n",
        "  print('[preprocess] started... ', end='')\r\n",
        "\r\n",
        "  # create sentences by replacing <word/> words\r\n",
        "  for row_idx, row in df.iterrows():\r\n",
        "    original = row['original1'].strip()\r\n",
        "    orig_word = re.search(\"<(.*)/>\", original)\r\n",
        "    orig_seq = f'{tokenizer.sep_token} {orig_word} {tokenizer.sep_token}'\r\n",
        "    df.loc[row_idx, 'original'] = re.sub(\"<.*/>\", orig_seq, original)\r\n",
        "    for i in ['1', '2']:\r\n",
        "      edit_seq = f'{tokenizer.sep_token} {row[f\"edit{i}\"]} {tokenizer.sep_token}'\r\n",
        "      mask_seq = f'{tokenizer.sep_token} {tokenizer.mask_token} {tokenizer.sep_token}'\r\n",
        "      df.loc[row_idx, f'edit_sentence{i}'] = re.sub(\"<.*/>\", edit_seq, original)\r\n",
        "      df.loc[row_idx, f'masked{i}'] = re.sub(\"<.*/>\", mask_seq, original)\r\n",
        "\r\n",
        "  # keep only the relevant columns  \r\n",
        "  cols_to_drop = list(df.columns)\r\n",
        "  for i in ['1', '2']:\r\n",
        "    cols_to_drop.remove(f'edit_sentence{i}')\r\n",
        "    cols_to_drop.remove(f'masked{i}')\r\n",
        "    cols_to_drop.remove(f'meanGrade{i}')\r\n",
        "  cols_to_drop.remove('original')\r\n",
        "  cols_to_drop.remove('label')\r\n",
        "  df = df.drop(columns=cols_to_drop)\r\n",
        "\r\n",
        "  print('done.')\r\n",
        "  return df\r\n",
        "\r\n",
        "def pad_column(col):\r\n",
        "  max_len = max([len(x) for x in col])\r\n",
        "  for k, v in enumerate(col):\r\n",
        "    col[k] += [tokenizer.pad_token_id] * (max_len - len(v))\r\n",
        "  return col\r\n",
        "\r\n",
        "def pad_batch(batch):\r\n",
        "  x_edit_1 = pad_column([row['x_edit_1'] for row in batch])\r\n",
        "  x_masked_1 = pad_column([row['x_masked_1'] for row in batch])\r\n",
        "  y_grade_1 = [row['y_grade_1'] for row in batch]\r\n",
        "  x_edit_2 = pad_column([row['x_edit_2'] for row in batch])\r\n",
        "  x_masked_2 = pad_column([row['x_masked_2'] for row in batch])\r\n",
        "  y_grade_2 = [row['y_grade_2'] for row in batch]\r\n",
        "  x_original = pad_column([row['x_original'] for row in batch])\r\n",
        "  y_label = [row['y_label'] for row in batch]\r\n",
        "  return {'x_edit_1': x_edit_1, 'x_masked_1': x_masked_1, 'y_grade_1': y_grade_1,\r\n",
        "          'x_edit_2': x_edit_2, 'x_masked_2': x_masked_2, 'y_grade_2': y_grade_2,\r\n",
        "          'x_original': x_original, 'y_label': y_label}\r\n",
        "\r\n",
        "\r\n",
        "# Load data from CSV\r\n",
        "train_df = pd.read_csv('data/task-2/train.csv')\r\n",
        "funlines_df = pd.read_csv('data/funlines/train_funlines.csv')\r\n",
        "test_df = pd.read_csv('data/task-2/dev.csv')\r\n",
        "print('Data loaded from CSV.')\r\n",
        "\r\n",
        "# Preprocess the data -> creates 2x (edit_sentence, masked_sentence, grade) + original + label\r\n",
        "funlines_df = preprocess_data(funlines_df)\r\n",
        "train_df = preprocess_data(train_df)\r\n",
        "dataframe = pd.concat([train_df, funlines_df])\r\n",
        "dataset = Task2Dataset(dataframe)\r\n",
        "print('Dataset created.')\r\n",
        "\r\n",
        "# Perform the train/eval split\r\n",
        "train_size = round(len(dataset) * TRAINING_RATIO)\r\n",
        "eval_size = len(dataset) - train_size\r\n",
        "train_dataset, eval_dataset = random_split(dataset, (train_size, eval_size))\r\n",
        "\r\n",
        "# Create data loaders\r\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=pad_batch)\r\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, collate_fn=pad_batch)\r\n",
        "print('Train and evaluation split data loaders generated.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded from CSV.\n",
            "[preprocess] started... done.\n",
            "[preprocess] started... done.\n",
            "Dataset created.\n",
            "Train and evaluation split data loaders generated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMXNuuzJX8a7"
      },
      "source": [
        "# DEFINE MODEL\r\n",
        "\r\n",
        "class ColBERT(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, tokenizer, transformer, context=False, classification=False):\r\n",
        "    super(ColBERT, self).__init__()\r\n",
        "    self.tokenizer = tokenizer\r\n",
        "    self.transformer = transformer\r\n",
        "    self.context = context                # combine edits with context\r\n",
        "    self.classification = classification  # use classfication head\r\n",
        "\r\n",
        "    hid_size = transformer.config.hidden_size\r\n",
        "    feature_size = 4\r\n",
        "\r\n",
        "    if not self.classification:\r\n",
        "      self.head = nn.Linear(hid_size * (feature_size if self.context else 1), 1)\r\n",
        "    else:\r\n",
        "      self.head = nn.Sequential(\r\n",
        "          nn.Dropout(0.2),\r\n",
        "          nn.Linear(hid_size * feature_size, 3))\r\n",
        "\r\n",
        "    if self.context and self.classification:\r\n",
        "      self.pool = nn.Linear(hid_size * feature_size * 2, hid_size * feature_size)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, edit1, context1, edit2, context2):\r\n",
        "    if self.context:\r\n",
        "      if self.classification:\r\n",
        "        return self._classify_context(edit1, context1, edit2, context2)\r\n",
        "      else:\r\n",
        "        return self._regress_context(edit1, context1, edit2, context2)\r\n",
        "    else:\r\n",
        "      if self.classification:\r\n",
        "        return self._classify(edit1, edit2)\r\n",
        "      else:\r\n",
        "        return self._regress(edit1, edit2)      \r\n",
        "    raise Exception('Invalid model config')\r\n",
        "\r\n",
        "  def _regress_context(self, edit1, context1, edit2, context2):\r\n",
        "    edit1_emb, edit2_emb = self._embed(edit1), self._embed(edit2)\r\n",
        "    context1_emb, context2_emb = self._embed(context1), self._embed(context2)\r\n",
        "    h1 = self._make_feature(edit1_emb, context1_emb)\r\n",
        "    h2 = self._make_feature(edit2_emb, context2_emb)\r\n",
        "    grade1 = self.head(h1).squeeze()\r\n",
        "    grade2 = self.head(h2).squeeze()\r\n",
        "    return self._soft_argmax(grade1, grade2), grade1, grade2\r\n",
        "  \r\n",
        "  def _regress(self, edit1, edit2):\r\n",
        "    edit1_emb = self._embed(edit1)\r\n",
        "    edit2_emb = self._embed(edit2)\r\n",
        "    grade1 = self.head(edit1_emb).squeeze()\r\n",
        "    grade2 = self.head(edit2_emb).squeeze()\r\n",
        "    return self._soft_argmax(grade1, grade2), grade1, grade2\r\n",
        "  \r\n",
        "  def _classify_context(self, edit1, context1, edit2, context2):\r\n",
        "    edit1_emb = self._embed(edit1)\r\n",
        "    edit2_emb = self._embed(edit2)\r\n",
        "    context1_emb = self._embed(context1)\r\n",
        "    context2_emb = self._embed(context2)\r\n",
        "    h1 = self._make_feature(edit1_emb, context1_emb)\r\n",
        "    h2 = self._make_feature(edit2_emb, context2_emb)\r\n",
        "    h = self.pool(torch.cat([h1, h2], -1))\r\n",
        "    return self.head(h), None, None\r\n",
        "    \r\n",
        "  def _classify(self, edit1, edit2):\r\n",
        "    edit1_emb = self._embed(edit1)\r\n",
        "    edit2_emb = self._embed(edit2)\r\n",
        "    h = self._make_feature(edit1_emb, edit2_emb)\r\n",
        "    return self.head(h), None, None\r\n",
        "  \r\n",
        "  def _embed(self, inp):\r\n",
        "    inp_mask = (inp != self.tokenizer.pad_token_id) & (inp != self.tokenizer.sep_token_id)\r\n",
        "    sep_mask = inp == self.tokenizer.sep_token_id\r\n",
        "        \r\n",
        "    outputs = self.transformer(inp, attention_mask=inp_mask)\r\n",
        "    last_hidden_state = outputs.last_hidden_state\r\n",
        "\r\n",
        "    span = torch.nonzero(input=sep_mask, as_tuple=True)[1].view(-1, 2)\r\n",
        "    span_mask = get_span_mask(span=span, sent_len=inp.shape[-1])\r\n",
        "\r\n",
        "    out = self._pool(last_hidden_state, span_mask)\r\n",
        "\r\n",
        "    return out\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def _make_feature(u, v):\r\n",
        "    return torch.cat([u, v, (u - v).abs(), u * v], -1)\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def _pool(sequence, mask):\r\n",
        "    if len(sequence.shape) == 2:\r\n",
        "      return sequence\r\n",
        "    if mask is None:\r\n",
        "      mask = torch.ones(sequence.shape[:2], device=device)\r\n",
        "    if len(mask.size()) < 3:\r\n",
        "      mask = mask.unsqueeze(dim=-1)\r\n",
        "    pad_mask = mask == 0\r\n",
        "    sequence = sequence.masked_fill(pad_mask, 0)\r\n",
        "    seq_emb = sequence.sum(dim=1) / mask.sum(dim=1).float()\r\n",
        "    return seq_emb\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def _soft_argmax(u, v, threshold=None):\r\n",
        "    \"Assign 0 instead of 1 (for u) or 2 (for v) if difference below threshold\"\r\n",
        "    argmax = torch.argmax(torch.stack([u, v], -1), dim=-1) + 1\r\n",
        "    if not threshold:\r\n",
        "      return argmax\r\n",
        "    diff_mask = (u - v).abs() <= threshold\r\n",
        "    return argmax.masked_fill(diff_mask, 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw539pIWcMfc"
      },
      "source": [
        "# How we print the model performance\r\n",
        "def model_performance(output, target, size, print_output=False):\r\n",
        "    \"\"\"\r\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    correct_answers = (output == target)\r\n",
        "    correct = sum(correct_answers)\r\n",
        "    acc = np.true_divide(correct, size)\r\n",
        "\r\n",
        "    if print_output:\r\n",
        "        print(f'| Acc: {acc:.2f} ')\r\n",
        "\r\n",
        "    return correct, acc"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3uaCGQZcO1P"
      },
      "source": [
        "# We evaluate performance on our dev set\r\n",
        "def eval(data_iter, model, context_type='none', classification=False):\r\n",
        "    \"\"\"\r\n",
        "    Evaluating model performance on the dev set\r\n",
        "    \"\"\"\r\n",
        "    model.eval()\r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_correct = 0\r\n",
        "    pred_all = []\r\n",
        "    trg_all = []\r\n",
        "    no_observations = 0\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for batch in data_iter:\r\n",
        "  \r\n",
        "          # Extract relevant data fields and cast to tensors\r\n",
        "          edit1 = torch.LongTensor(batch['x_edit_1']).to(device)\r\n",
        "          edit2 = torch.LongTensor(batch['x_edit_2']).to(device)\r\n",
        "          y_label_true = torch.LongTensor(batch['y_label']).to(device)\r\n",
        "          if context_type == 'masked':\r\n",
        "            context1 = torch.LongTensor(batch['x_masked_1']).to(device)\r\n",
        "            context2 = torch.LongTensor(batch['x_masked_2']).to(device)\r\n",
        "          elif context_type == 'original':\r\n",
        "            context1 = context2 = torch.LongTensor(batch['x_original']).to(device)\r\n",
        "          else:\r\n",
        "            context1 = context2 = None\r\n",
        "    \r\n",
        "          if classification:\r\n",
        "            y_grade1_true = y_grade2_true = None\r\n",
        "          else:\r\n",
        "            y_grade1_true = torch.FloatTensor(batch['y_grade_1']).to(device)\r\n",
        "            y_grade2_true = torch.FloatTensor(batch['y_grade_2']).to(device)\r\n",
        "      \r\n",
        "          batch_len = len(y_label_true)\r\n",
        "          optimizer.zero_grad()\r\n",
        "\r\n",
        "          # Forward pass\r\n",
        "          y_label_pred, y_grade1_pred, y_grade2_pred = model(edit1, context1, edit2, context2)\r\n",
        "    \r\n",
        "          # Calculate regression loss\r\n",
        "          if not classification:\r\n",
        "            if batch_len == 1:\r\n",
        "              y_grade1_pred = y_grade1_pred.unsqueeze(-1)\r\n",
        "              y_grade2_pred = y_grade2_pred.unsqueeze(-1)\r\n",
        "            loss_fn = nn.MSELoss(reduction=\"sum\")\r\n",
        "            loss1 = loss_fn(y_grade1_pred, y_grade1_true)\r\n",
        "            loss2 = loss_fn(y_grade2_pred, y_grade2_true)\r\n",
        "            loss = (loss1 + loss2)\r\n",
        "            label_preds = y_label_pred.detach().cpu().numpy()\r\n",
        "          # Calculate classification loss\r\n",
        "          else:\r\n",
        "            loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\r\n",
        "            loss = loss_fn(y_label_pred, y_label_true)\r\n",
        "            label_preds = torch.argmax(y_label_pred.detach().cpu(), dim=-1).numpy()\r\n",
        "\r\n",
        "          # Logging\r\n",
        "          correct, __ = model_performance(label_preds, y_label_true.detach().cpu().numpy(), batch_len)\r\n",
        "          epoch_loss += loss.item()\r\n",
        "          epoch_correct += correct\r\n",
        "          no_observations += batch_len\r\n",
        "\r\n",
        "    return epoch_loss/no_observations, epoch_correct/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XlG7CvT0Blj"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, optimizer, number_epoch=10, context_type='none',\n",
        "          classification=False):\n",
        "  \"\"\"\n",
        "  Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "  \"\"\"\n",
        "\n",
        "  print(f\"Training model - classification {classification}, context {context_type}\")\n",
        "  train_losses, valid_losses = [], []\n",
        "  train_accs, valid_accs = [], []\n",
        "\n",
        "  for epoch in range(1, number_epoch+1):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_correct = 0\n",
        "    no_observations = 0  # Observations used for training so far\n",
        "\n",
        "    for batch in train_iter:\n",
        "\n",
        "      # Extract relevant data fields and cast to tensors\n",
        "      edit1 = torch.LongTensor(batch['x_edit_1']).to(device)\n",
        "      edit2 = torch.LongTensor(batch['x_edit_2']).to(device)\n",
        "      y_label_true = torch.LongTensor(batch['y_label']).to(device)\n",
        "      if context_type == 'masked':\n",
        "        context1 = torch.LongTensor(batch['x_masked_1']).to(device)\n",
        "        context2 = torch.LongTensor(batch['x_masked_2']).to(device)\n",
        "      elif context_type == 'original':\n",
        "        context1 = context2 = torch.LongTensor(batch['x_original']).to(device)\n",
        "      else:\n",
        "        context1 = context2 = None\n",
        "\n",
        "      if classification:\n",
        "        y_grade1_true = y_grade2_true = None\n",
        "      else:\n",
        "        y_grade1_true = torch.FloatTensor(batch['y_grade_1']).to(device)\n",
        "        y_grade2_true = torch.FloatTensor(batch['y_grade_2']).to(device)\n",
        "  \n",
        "      batch_len = len(y_label_true)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      y_label_pred, y_grade1_pred, y_grade2_pred = model(edit1, context1, edit2, context2)\n",
        "\n",
        "      # Calculate regression loss\n",
        "      if not classification:\n",
        "        if batch_len == 1:\n",
        "          y_grade1_pred = y_grade1_pred.unsqueeze(-1)\n",
        "          y_grade2_pred = y_grade2_pred.unsqueeze(-1)\n",
        "        loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "        loss1 = loss_fn(y_grade1_pred, y_grade1_true)\n",
        "        loss2 = loss_fn(y_grade2_pred, y_grade2_true)\n",
        "        loss = (loss1 + loss2)\n",
        "        label_preds = y_label_pred.detach().cpu().numpy()\n",
        "      # Calculate classification loss\n",
        "      else:\n",
        "        loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "        loss = loss_fn(y_label_pred, y_label_true)\n",
        "        label_preds = torch.argmax(y_label_pred.detach().cpu(), dim=-1).numpy()\n",
        "\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      sum_grad = 0\n",
        "      clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
        "      optimizer.step()\n",
        "\n",
        "      # Logging\n",
        "      correct, __ = model_performance(label_preds, y_label_true.detach().cpu().numpy(), batch_len)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_correct += correct\n",
        "      no_observations += batch_len\n",
        "  \n",
        "    valid_loss, valid_acc, __, __ = eval(dev_iter, model, context_type, classification)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accs.append(valid_acc)\n",
        "\n",
        "    epoch_loss, epoch_acc = epoch_loss / no_observations, epoch_correct / no_observations\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accs.append(epoch_acc)\n",
        "  \n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train Accuracy: {epoch_acc:.2f} | \\\n",
        "    Val. Loss: {valid_loss:.2f} | Val. Accuracy: {valid_acc:.2f} |')\n",
        "  \n",
        "  fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10,4))\n",
        "  ax[0].plot(train_losses, label='Training losses')\n",
        "  ax[0].plot(valid_losses, label='Validation losses')\n",
        "  ax[0].legend()\n",
        "  ax[1].plot(train_accs, label='Training accuracies')\n",
        "  ax[1].plot(valid_accs, label='Validation accuracies')\n",
        "  ax[0].legend()\n",
        "  fig.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr1RqWfPB_cv",
        "outputId": "31c3f1f4-4469-4a4a-9aa3-5161cece2259"
      },
      "source": [
        "# Regression, no context\r\n",
        "#| Epoch: 10 | Train Loss: 0.37 | Train Accuracy: 0.57 |     Val. Loss: 0.59 | Val. Accuracy: 0.62 |\r\n",
        "\r\n",
        "# Classification, no context\r\n",
        "#| Epoch: 05 | Train Loss: 0.62 | Train Accuracy: 0.76 |     Val. Loss: 0.93 | Val. Accuracy: 0.62 |\r\n",
        "\r\n",
        "\r\n",
        "### Run tests\r\n",
        "\r\n",
        "for context_type in context_types[1:]:\r\n",
        "  for classification in [False, True]:\r\n",
        "    transformer.init_weights()\r\n",
        "    model = ColBERT(tokenizer, transformer, context_type != 'none', classification).to(device)\r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, eps=ADAM_EPSILON)\r\n",
        "    train(train_loader, eval_loader, model, optimizer, EPOCHS, context_type, classification)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model - classification False, context masked\n",
            "| Epoch: 01 | Train Loss: 0.89 | Train Accuracy: 0.46 |     Val. Loss: 0.69 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 02 | Train Loss: 0.67 | Train Accuracy: 0.54 |     Val. Loss: 0.69 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 03 | Train Loss: 0.52 | Train Accuracy: 0.61 |     Val. Loss: 0.65 | Val. Accuracy: 0.59 |\n",
            "| Epoch: 04 | Train Loss: 0.41 | Train Accuracy: 0.64 |     Val. Loss: 0.54 | Val. Accuracy: 0.59 |\n",
            "| Epoch: 05 | Train Loss: 0.34 | Train Accuracy: 0.67 |     Val. Loss: 0.52 | Val. Accuracy: 0.61 |\n",
            "| Epoch: 06 | Train Loss: 0.28 | Train Accuracy: 0.69 |     Val. Loss: 0.47 | Val. Accuracy: 0.61 |\n",
            "| Epoch: 07 | Train Loss: 0.25 | Train Accuracy: 0.71 |     Val. Loss: 0.62 | Val. Accuracy: 0.63 |\n",
            "| Epoch: 08 | Train Loss: 0.22 | Train Accuracy: 0.73 |     Val. Loss: 0.44 | Val. Accuracy: 0.63 |\n",
            "| Epoch: 09 | Train Loss: 0.19 | Train Accuracy: 0.74 |     Val. Loss: 0.44 | Val. Accuracy: 0.64 |\n",
            "| Epoch: 10 | Train Loss: 0.16 | Train Accuracy: 0.76 |     Val. Loss: 0.44 | Val. Accuracy: 0.66 |\n",
            "Training model - classification True, context masked\n",
            "| Epoch: 01 | Train Loss: 1.08 | Train Accuracy: 0.44 |     Val. Loss: 0.96 | Val. Accuracy: 0.46 |\n",
            "| Epoch: 02 | Train Loss: 1.06 | Train Accuracy: 0.46 |     Val. Loss: 1.01 | Val. Accuracy: 0.47 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihbNoQ7DUoJD"
      },
      "source": [
        "```\r\n",
        "Training model - classification False, context none\r\n",
        "| Epoch: 01 | Train Loss: 0.87 | Train Accuracy: 0.46 |     Val. Loss: 0.84 | Val. Accuracy: 0.50 |\r\n",
        "| Epoch: 02 | Train Loss: 0.62 | Train Accuracy: 0.55 |     Val. Loss: 0.60 | Val. Accuracy: 0.55 |\r\n",
        "| Epoch: 03 | Train Loss: 0.47 | Train Accuracy: 0.61 |     Val. Loss: 0.54 | Val. Accuracy: 0.58 |\r\n",
        "| Epoch: 04 | Train Loss: 0.37 | Train Accuracy: 0.65 |     Val. Loss: 0.54 | Val. Accuracy: 0.60 |\r\n",
        "| Epoch: 05 | Train Loss: 0.30 | Train Accuracy: 0.68 |     Val. Loss: 0.47 | Val. Accuracy: 0.62 |\r\n",
        "| Epoch: 06 | Train Loss: 0.24 | Train Accuracy: 0.71 |     Val. Loss: 0.45 | Val. Accuracy: 0.63 |\r\n",
        "| Epoch: 07 | Train Loss: 0.20 | Train Accuracy: 0.73 |     Val. Loss: 0.45 | Val. Accuracy: 0.64 |\r\n",
        "| Epoch: 08 | Train Loss: 0.16 | Train Accuracy: 0.76 |     Val. Loss: 0.50 | Val. Accuracy: 0.65 |\r\n",
        "| Epoch: 09 | Train Loss: 0.13 | Train Accuracy: 0.77 |     Val. Loss: 0.42 | Val. Accuracy: 0.67 |\r\n",
        "| Epoch: 10 | Train Loss: 0.11 | Train Accuracy: 0.79 |     Val. Loss: 0.42 | Val. Accuracy: 0.68 |\r\n",
        "Training model - classification True, context none\r\n",
        "| Epoch: 01 | Train Loss: 1.02 | Train Accuracy: 0.44 |     Val. Loss: 0.96 | Val. Accuracy: 0.47 |\r\n",
        "| Epoch: 02 | Train Loss: 0.98 | Train Accuracy: 0.48 |     Val. Loss: 0.96 | Val. Accuracy: 0.47 |\r\n",
        "| Epoch: 03 | Train Loss: 0.91 | Train Accuracy: 0.58 |     Val. Loss: 0.97 | Val. Accuracy: 0.55 |\r\n",
        "| Epoch: 04 | Train Loss: 0.78 | Train Accuracy: 0.68 |     Val. Loss: 0.95 | Val. Accuracy: 0.56 |\r\n",
        "| Epoch: 05 | Train Loss: 0.67 | Train Accuracy: 0.74 |     Val. Loss: 1.11 | Val. Accuracy: 0.58 |\r\n",
        "| Epoch: 06 | Train Loss: 0.58 | Train Accuracy: 0.78 |     Val. Loss: 1.12 | Val. Accuracy: 0.57 |\r\n",
        "| Epoch: 07 | Train Loss: 0.49 | Train Accuracy: 0.81 |     Val. Loss: 1.24 | Val. Accuracy: 0.59 |\r\n",
        "| Epoch: 08 | Train Loss: 0.41 | Train Accuracy: 0.84 |     Val. Loss: 1.27 | Val. Accuracy: 0.56 |\r\n",
        "| Epoch: 09 | Train Loss: 0.34 | Train Accuracy: 0.87 |     Val. Loss: 1.49 | Val. Accuracy: 0.51 |\r\n",
        "| Epoch: 10 | Train Loss: 0.26 | Train Accuracy: 0.90 |     Val. Loss: 1.64 | Val. Accuracy: 0.54 |\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4PGG50gUpbe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDQvwoea0Blk"
      },
      "source": [
        " # To create our vocab\n",
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        tokenized_sentence = []\n",
        "\n",
        "        for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "            tokenized_sentence.append(token)\n",
        "\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9KJdW440Bll"
      },
      "source": [
        "# Used for collating our observations into minibatches:\n",
        "def collate_fn_padd(batch):\n",
        "    '''\n",
        "    We add padding to our minibatches and create tensors for our model\n",
        "    '''\n",
        "\n",
        "    batch_labels = [l for f, l in batch]\n",
        "    batch_features = [f for f, l in batch]\n",
        "\n",
        "    batch_features_len = [len(f) for f, l in batch]\n",
        "\n",
        "    seq_tensor = torch.zeros((len(batch), max(batch_features_len))).long()\n",
        "\n",
        "    for idx, (seq, seqlen) in enumerate(zip(batch_features, batch_features_len)):\n",
        "        seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "    batch_labels = torch.LongTensor(batch_labels)\n",
        "\n",
        "    return seq_tensor, batch_labels\n",
        "\n",
        "# We create a Dataset so we can create minibatches\n",
        "class Task2Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, train_data, labels):\n",
        "        self.x_train = train_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train[item], self.y_train[item]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H54iG8X0Bll"
      },
      "source": [
        "\n",
        "class BiLSTM_classification(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, batch_size, device):\n",
        "        super(BiLSTM_classification, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.device = device\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2label = nn.Linear(hidden_dim * 2, 3)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device), \\\n",
        "               torch.zeros(2, self.batch_size, self.hidden_dim).to(self.device)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embedded = self.embedding(sentence)\n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            embedded.view(len(embedded), self.batch_size, self.embedding_dim), self.hidden)\n",
        "\n",
        "        out = self.hidden2label(lstm_out[-1])\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV4eurVH0Bll",
        "outputId": "ea06e2c0-200a-47de-ee6d-8fdb119045d5"
      },
      "source": [
        "## Approach 1 code, using functions defined above:\n",
        "\n",
        "# We set our training data and test data\n",
        "training_data = train_df['original1']\n",
        "test_data = test_df['original1']\n",
        "\n",
        "# Creating word vectors\n",
        "training_vocab, training_tokenized_corpus = create_vocab(training_data)\n",
        "test_vocab, test_tokenized_corpus = create_vocab(test_data)\n",
        "\n",
        "# Creating joint vocab from test and train:\n",
        "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([training_data, test_data]))\n",
        "\n",
        "print(\"Vocab created.\")\n",
        "\n",
        "# We create representations for our tokens\n",
        "wvecs = [] # word vectors\n",
        "word2idx = [] # word2index\n",
        "idx2word = []\n",
        "\n",
        "# This is a large file, it will take a while to load in the memory!\n",
        "with codecs.open('glove.6B.100d.txt', 'r','utf-8') as f:\n",
        "  index = 1\n",
        "  for line in f.readlines():\n",
        "    # Ignore the first line - first line typically contains vocab, dimensionality\n",
        "    if len(line.strip().split()) > 3:\n",
        "      word = line.strip().split()[0]\n",
        "      if word in joint_vocab:\n",
        "          (word, vec) = (word,\n",
        "                     list(map(float,line.strip().split()[1:])))\n",
        "          wvecs.append(vec)\n",
        "          word2idx.append((word, index))\n",
        "          idx2word.append((index, word))\n",
        "          index += 1\n",
        "\n",
        "\n",
        "wvecs = np.array(wvecs)\n",
        "word2idx = dict(word2idx)\n",
        "idx2word = dict(idx2word)\n",
        "\n",
        "vectorized_seqs = [[word2idx[tok] for tok in seq if tok in word2idx] for seq in training_tokenized_corpus]\n",
        "\n",
        "INPUT_DIM = len(word2idx)\n",
        "EMBEDDING_DIM = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "model = BiLSTM_classification(EMBEDDING_DIM, 50, INPUT_DIM, BATCH_SIZE, device)\n",
        "print(\"Model initialised.\")\n",
        "\n",
        "model.to(device)\n",
        "# We provide the model with our embeddings\n",
        "model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
        "\n",
        "feature = vectorized_seqs\n",
        "\n",
        "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
        "train_and_dev = Task2Dataset(feature, train_df['label'])\n",
        "\n",
        "train_examples = round(len(train_and_dev)*train_proportion)\n",
        "dev_examples = len(train_and_dev) - train_examples\n",
        "\n",
        "train_dataset, dev_dataset = random_split(train_and_dev,\n",
        "                                           (train_examples,\n",
        "                                            dev_examples))\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "print(\"Dataloaders created.\")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "train(train_loader, dev_loader, model, epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab created.\n",
            "Model initialised.\n",
            "Dataloaders created.\n",
            "Training model.\n",
            "| Epoch: 01 | Train Loss: 0.96 | Train Accuracy: 0.44 |         Val. Loss: 0.98 | Val. Accuracy: 0.43 |\n",
            "| Epoch: 02 | Train Loss: 0.96 | Train Accuracy: 0.45 |         Val. Loss: 0.97 | Val. Accuracy: 0.45 |\n",
            "| Epoch: 03 | Train Loss: 0.96 | Train Accuracy: 0.45 |         Val. Loss: 0.97 | Val. Accuracy: 0.43 |\n",
            "| Epoch: 04 | Train Loss: 0.95 | Train Accuracy: 0.46 |         Val. Loss: 0.98 | Val. Accuracy: 0.43 |\n",
            "| Epoch: 05 | Train Loss: 0.94 | Train Accuracy: 0.52 |         Val. Loss: 0.99 | Val. Accuracy: 0.46 |\n",
            "| Epoch: 06 | Train Loss: 0.87 | Train Accuracy: 0.60 |         Val. Loss: 1.02 | Val. Accuracy: 0.48 |\n",
            "| Epoch: 07 | Train Loss: 0.80 | Train Accuracy: 0.62 |         Val. Loss: 1.05 | Val. Accuracy: 0.49 |\n",
            "| Epoch: 08 | Train Loss: 0.75 | Train Accuracy: 0.65 |         Val. Loss: 1.16 | Val. Accuracy: 0.47 |\n",
            "| Epoch: 09 | Train Loss: 0.70 | Train Accuracy: 0.66 |         Val. Loss: 1.18 | Val. Accuracy: 0.48 |\n",
            "| Epoch: 10 | Train Loss: 0.66 | Train Accuracy: 0.67 |         Val. Loss: 1.27 | Val. Accuracy: 0.48 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oatMnFeB0Bln"
      },
      "source": [
        "#### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NUlZmidx0Bln",
        "outputId": "37988061-d2c7-4222-c022-0993d4f4f63f"
      },
      "source": [
        "train_and_dev = train_df['edit1']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit1'], train_df['label'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "naive_model = MultinomialNB().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = naive_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = naive_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train performance:\n",
            "| Acc: 0.73 \n",
            "\n",
            "Dev performance:\n",
            "| Acc: 0.52 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYG40gkY0Bln"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmzYO2i10Bln",
        "outputId": "8d787f42-fe66-442f-e877-aa1decc60a96"
      },
      "source": [
        "# Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + 1  # 1 is most common class\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, torch.tensor(dev_y.values), True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Baseline performance:\n",
            "| Acc: 0.45 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XdB-5_I0Blo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKJ0AOd00Blo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}