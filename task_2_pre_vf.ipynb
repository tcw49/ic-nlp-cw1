{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_2_pre_vf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "gradient": {
          "editing": false
        },
        "id": "LO114qTM0Blf"
      },
      "source": [
        "### Coursework coding instructions (please also see full coursework spec)\n",
        "\n",
        "Please choose if you want to do either Task 1 or Task 2. You should write your report about one task only.\n",
        "\n",
        "For the task you choose you will need to do two approaches:\n",
        "  - Approach 1, which can use use pre-trained embeddings / models\n",
        "  - Approach 2, which should not use any pre-trained embeddings or models\n",
        "We should be able to run both approaches from the same colab file\n",
        "\n",
        "#### Running your code:\n",
        "  - Your models should run automatically when running your colab file without further intervention\n",
        "  - For each task you should automatically output the performance of both models\n",
        "  - Your code should automatically download any libraries required\n",
        "\n",
        "#### Structure of your code:\n",
        "  - You are expected to use the 'train', 'eval' and 'model_performance' functions, although you may edit these as required\n",
        "  - Otherwise there are no restrictions on what you can do in your code\n",
        "\n",
        "#### Documentation:\n",
        "  - You are expected to produce a .README file summarising how you have approached both tasks\n",
        "\n",
        "#### Reproducibility:\n",
        "  - Your .README file should explain how to replicate the different experiments mentioned in your report\n",
        "\n",
        "Good luck! We are really looking forward to seeing your reports and your model code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTI4vyDLPuQd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIjQ_XK0PbaY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKqe4drh0Blg",
        "outputId": "c7380103-3549-4d92-ee20-ada6263a8088"
      },
      "source": [
        "# You will need to download any word embeddings required for your code, e.g.:\n",
        "\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip glove.6B.zip\n",
        "\n",
        "# For any packages that Colab does not provide auotmatically you will also need to install these below, e.g.:\n",
        "\n",
        "#! pip install torch\n",
        "%pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cz1Gndw3Y17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d70ef9-3921-4887-834c-2dd7dd04b31f"
      },
      "source": [
        "# Download the task dataset\n",
        "\n",
        "!wget https://www.cs.rochester.edu/u/nhossain/humicroedit/semeval-2020-task-7-data-full.zip\n",
        "!unzip semeval-2020-task-7-data-full.zip\n",
        "!rm semeval-2020-task-7-data-full.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-01 22:51:01--  https://www.cs.rochester.edu/u/nhossain/humicroedit/semeval-2020-task-7-data-full.zip\n",
            "Resolving www.cs.rochester.edu (www.cs.rochester.edu)... 192.5.53.208\n",
            "Connecting to www.cs.rochester.edu (www.cs.rochester.edu)|192.5.53.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1175243 (1.1M) [application/zip]\n",
            "Saving to: ‘semeval-2020-task-7-data-full.zip’\n",
            "\n",
            "semeval-2020-task-7 100%[===================>]   1.12M  2.14MB/s    in 0.5s    \n",
            "\n",
            "2021-03-01 22:51:02 (2.14 MB/s) - ‘semeval-2020-task-7-data-full.zip’ saved [1175243/1175243]\n",
            "\n",
            "Archive:  semeval-2020-task-7-data-full.zip\n",
            "replace semeval-2020-task-7-data-full/task-1/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT-EZhC50Blh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb081d45-e41d-46ac-b756-8880cb77ca2e"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torch.utils.data import Dataset, random_split\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import torch.optim as optim\n",
        "import codecs\n",
        "import tqdm\n",
        "import random\n",
        "\n",
        "# More imports\n",
        "%pip install transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertPreTrainedModel, BertModel"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REQlB22W0Blh"
      },
      "source": [
        "# Setting random seed and device\n",
        "SEED = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsy2mTFt0Bli"
      },
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('semeval-2020-task-7-data-full/task-2/train.csv')\n",
        "val_df = pd.read_csv('semeval-2020-task-7-data-full/task-2/dev.csv')\n",
        "test_df = pd.read_csv('semeval-2020-task-7-data-full/task-2/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcYqpAIXkkuP"
      },
      "source": [
        "#Delete rows with labels 0\n",
        "train_df = train_df[train_df.label != 0]\n",
        "train_df.label = train_df.label - 1\n",
        "\n",
        "#Delete rows with labels 0\n",
        "val_df = val_df[val_df.label != 0]\n",
        "val_df.label = val_df.label - 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR9qzBjJ0Bli"
      },
      "source": [
        "# Number of epochs\n",
        "epochs = 10\n",
        "\n",
        "# Proportion of training data for train compared to dev\n",
        "train_proportion = 0.8\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEo6YgMnqk8A"
      },
      "source": [
        "#### BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58a7a62BtndA"
      },
      "source": [
        "##### Make BERT works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elMRsCQ70Bli"
      },
      "source": [
        "#### Approach 1: Using pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XlG7CvT0Blj"
      },
      "source": [
        "# We define our training loop\n",
        "def train(train_iter, dev_iter, model, number_epoch, optimizer):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Training model.\")\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "        epoch_correct = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "        for batch in train_iter:\n",
        "\n",
        "            if model.__class__.__name__ == 'ColBERT':\n",
        "              # predictions if model is BERT\n",
        "              input_ids1, attention_mask1, input_ids2, attention_mask2, target = batch\n",
        "              target =  target.type(torch.FloatTensor)\n",
        "              input_ids1, attention_mask1, input_ids2, attention_mask2, target = input_ids1.to(device), attention_mask1.to(device), input_ids2.to(device), attention_mask2.to(device), target.to(device)\n",
        "              input_ids1 = input_ids1.squeeze(1)\n",
        "              attention_mask1 = attention_mask1.squeeze(1)\n",
        "              input_ids2 = input_ids2.squeeze(1)\n",
        "              attention_mask2 = attention_mask2.squeeze(1)\n",
        "\n",
        "              predictions = model(input_ids1, attention_mask1, input_ids2, attention_mask2).squeeze(1)\n",
        "\n",
        "            elif model.__class__.__name__ == 'BiLSTM_Attention':\n",
        "              X1, X2, target = batch\n",
        "              #target = target.type(torch.FloatTensor)\n",
        "              X1, X2, target = X1.to(device), X2.to(device), target.to(device)\n",
        "              model.batch_size = target.shape[0]\n",
        "              predictions = model(X1, X2).squeeze(1)\n",
        "          \n",
        "            else:\n",
        "              # predictions if model is not BERT\n",
        "              feature, target = batch\n",
        "              feature, target = feature.to(device), target.to(device)\n",
        "              # for RNN\n",
        "              model.batch_size = target.shape[0]\n",
        "              model.hidden = model.init_hidden()\n",
        "              predictions = model(feature).squeeze(1)\n",
        "\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            if model.__class__.__name__ == 'ColBERT':\n",
        "              correct, __ = model_performance(np.around(predictions.detach().cpu().numpy()), target.detach().cpu().numpy())\n",
        "            else:\n",
        "              correct, __ = model_performance(np.argmax(predictions.detach().cpu().numpy(), axis=1), target.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_correct += correct\n",
        "\n",
        "        valid_loss, valid_acc, __, __ = eval(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_acc = epoch_loss / no_observations, epoch_correct / no_observations\n",
        "        \n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train Accuracy: {epoch_acc:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. Accuracy: {valid_acc:.2f} |')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2MSILUg0Blj"
      },
      "source": [
        "# We evaluate performance on our dev set\n",
        "def eval(data_iter, model):\n",
        "    \"\"\"\n",
        "    Evaluating model performance on the dev set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_correct = 0\n",
        "    pred_all = []\n",
        "    trg_all = []\n",
        "    no_observations = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_iter:\n",
        "\n",
        "            if model.__class__.__name__ == 'ColBERT':\n",
        "\n",
        "              input_ids1, attention_mask1, input_ids2, attention_mask2, target = batch\n",
        "              target =  target.type(torch.FloatTensor)\n",
        "              input_ids1, attention_mask1, input_ids2, attention_mask2, target = input_ids1.to(device), attention_mask1.to(device), input_ids2.to(device), attention_mask2.to(device), target.to(device)\n",
        "              input_ids1 = input_ids1.squeeze(1)\n",
        "              attention_mask1 = attention_mask1.squeeze(1)\n",
        "              input_ids2 = input_ids2.squeeze(1)\n",
        "              attention_mask2 = attention_mask2.squeeze(1)\n",
        "\n",
        "              predictions = model(input_ids1, attention_mask1, input_ids2, attention_mask2).squeeze(1)\n",
        "\n",
        "            elif model.__class__.__name__ == 'BiLSTM_Attention':\n",
        "              X1, X2, target = batch\n",
        "              #target = target.type(torch.FloatTensor)\n",
        "              X1, X2, target = X1.to(device), X2.to(device), target.to(device)\n",
        "              model.batch_size = target.shape[0]\n",
        "              predictions = model(X1, X2).squeeze(1)\n",
        "          \n",
        "            else:\n",
        "              # predictions if model is not BERT\n",
        "              feature, target = batch\n",
        "              feature, target = feature.to(device), target.to(device)\n",
        "              model.hidden = model.init_hidden()\n",
        "              # for RNN:\n",
        "              model.batch_size = target.shape[0]\n",
        "              model.hidden = model.init_hidden()\n",
        "              predictions = model(feature).squeeze(1)\n",
        "\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            # We get the mse\n",
        "            pred, trg = np.around(predictions.detach().cpu().numpy()), target.detach().cpu().numpy()\n",
        "            if model.__class__.__name__ == 'ColBERT':\n",
        "              correct, __ = model_performance(pred, trg)\n",
        "            else:\n",
        "              correct, __ = model_performance(np.argmax(pred, axis=1), trg)\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_correct += correct\n",
        "            pred_all.extend(pred)\n",
        "            trg_all.extend(trg)\n",
        "\n",
        "    return epoch_loss/no_observations, epoch_correct/no_observations, np.array(pred_all), np.array(trg_all)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA03cmyL0Blk"
      },
      "source": [
        "# How we print the model performance\n",
        "def model_performance(output, target, print_output=False):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    correct_answers = (output == target)\n",
        "    correct = sum(correct_answers)\n",
        "    acc = np.true_divide(correct,len(output))\n",
        "\n",
        "    if print_output:\n",
        "        print(f'| Acc: {acc:.2f} ')\n",
        "\n",
        "    return correct, acc"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDQvwoea0Blk"
      },
      "source": [
        "# To create our vocab\n",
        "def create_vocab(data):\n",
        "    \"\"\"\n",
        "    Creating a corpus of all the tokens used\n",
        "    \"\"\"\n",
        "    tokenized_corpus = [] # Let us put the tokenized corpus in a list\n",
        "\n",
        "    for sentence in data:\n",
        "\n",
        "        tokenized_sentence = []\n",
        "\n",
        "        for token in sentence.split(' '): # simplest split is\n",
        "\n",
        "            tokenized_sentence.append(token)\n",
        "\n",
        "        tokenized_corpus.append(tokenized_sentence)\n",
        "\n",
        "    # Create single list of all vocabulary\n",
        "    vocabulary = []  # Let us put all the tokens (mostly words) appearing in the vocabulary in a list\n",
        "\n",
        "    for sentence in tokenized_corpus:\n",
        "\n",
        "        for token in sentence:\n",
        "\n",
        "            if token not in vocabulary:\n",
        "\n",
        "                if True:\n",
        "                    vocabulary.append(token)\n",
        "\n",
        "    return vocabulary, tokenized_corpus"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9KJdW440Bll"
      },
      "source": [
        "# Used for collating our observations into minibatches:\n",
        "def collate_fn_padd(batch):\n",
        "    '''\n",
        "    We add padding to our minibatches and create tensors for our model\n",
        "    '''\n",
        "\n",
        "    batch_labels = [l for f1, f2, l in batch]\n",
        "    batch_feature1 = [f1 for f1, f2, l in batch]\n",
        "    batch_feature2 = [f2 for f1, f2, l in batch]\n",
        "    batch_feature1_len = [len(f1) for f1, f2, l in batch]\n",
        "    batch_feature2_len = [len(f2) for f1, f2, l in batch]\n",
        "    max_batch_features_len = max(batch_feature1_len + batch_feature2_len)\n",
        "\n",
        "    seq1_tensor = torch.zeros((len(batch), max_batch_features_len)).long()\n",
        "    seq2_tensor = torch.zeros((len(batch), max_batch_features_len)).long()\n",
        "\n",
        "    for idx, (seq1, seq2, seq1len, seq2len) in \\\n",
        "    enumerate(zip(batch_feature1, batch_feature2, batch_feature1_len, batch_feature2_len)):\n",
        "      seq1_tensor[idx, :seq1len] = torch.LongTensor(seq1)\n",
        "      seq2_tensor[idx, :seq2len] = torch.LongTensor(seq2)\n",
        "\n",
        "    batch_labels = torch.LongTensor(batch_labels)\n",
        "    return seq1_tensor, seq2_tensor, batch_labels\n",
        "\n",
        "# We create a Dataset so we can create minibatches\n",
        "class Task2Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, train_data, labels):\n",
        "        self.x_train = train_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x_train[item], self.y_train[item]\n",
        "\n",
        "# We create a Dataset specific to BERT\n",
        "class Task2Dataset_BERT(Dataset):\n",
        "\n",
        "    def __init__(self, train1_data, train2_data, labels):\n",
        "        self.x1_train = train1_data\n",
        "        self.x2_train = train2_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x1_train[item]['input_ids'], self.x1_train[item]['attention_mask'], self.x2_train[item]['input_ids'], self.x2_train[item]['attention_mask'], self.y_train[item]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsxTQIPAYPwi"
      },
      "source": [
        "# Define the BERT model we will use\n",
        "# We preferred to use the cased one which allows to differentiate between \"trump\" and \"Trump\" (he is very present in this dataset)\n",
        "bert_model = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOXvatyCYSNl"
      },
      "source": [
        "class ColBERT(BertPreTrainedModel):\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "\n",
        "    # BERT model\n",
        "    self.bert = BertModel(config)\n",
        "    \n",
        "    # Classification layer\n",
        "    self.final_layer = torch.nn.Sequential(torch.nn.Dropout(0.2),\n",
        "                                           torch.nn.Linear(config.hidden_size , 1),\n",
        "                                           torch.nn.Sigmoid())\n",
        "    \n",
        "  def forward(\n",
        "    self,\n",
        "    input_ids1=None,\n",
        "    attention_mask1=None,\n",
        "    input_ids2=None,\n",
        "    attention_mask2=None):\n",
        " \n",
        "    outputs1 = self.bert(\n",
        "        input_ids1,\n",
        "        attention_mask=attention_mask1)\n",
        "    \n",
        "    outputs2 = self.bert(\n",
        "        input_ids2,\n",
        "        attention_mask=attention_mask2\n",
        "    )\n",
        "\n",
        "    diff = outputs1[1] - outputs2[1]\n",
        "\n",
        "    # outputs = torch.cat((outputs1[1], outputs2[1], abs), 1)\n",
        "\n",
        "    out = self.final_layer(diff)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1JodU55YT2C"
      },
      "source": [
        "import re\n",
        "\n",
        "def replace_word(sentence, new_word):\n",
        "  search = re.search(\"<(.*)/>\", sentence)\n",
        "  word_to_replace = \"<\" + search.group(1) + \"/>\"\n",
        "  # sentence = sentence.replace(word_to_replace,  new_word)\n",
        "  sentence = sentence.replace(word_to_replace, new_word)\n",
        "  return sentence"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seNAk_bKYVmu"
      },
      "source": [
        "def replace_word_dataset(sentence_dataset, word_dataset):\n",
        "  new_dataset = []\n",
        "  for i in range (len(sentence_dataset)):\n",
        "    new_sentence = replace_word(sentence_dataset[i], word_dataset[i])\n",
        "    new_dataset.append(new_sentence)\n",
        "  return new_dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7TvO3P2Ygec"
      },
      "source": [
        "# Returns inputs_id and attention_mask for each sentence of the dataset\n",
        "def tokenized_dataset(dataset):\n",
        "  tokenized = []\n",
        "  for i in range(len(dataset)):\n",
        "    encoding = tokenizer.encode_plus(dataset[i], max_length=73, return_token_type_ids=False, pad_to_max_length=True, return_attention_mask=True, return_tensors='pt')\n",
        "    tokenized.append(encoding)\n",
        "  return tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB4vk-T2WV1S"
      },
      "source": [
        "# Split into training and evaluation dataset\n",
        "def get_train_and_eval(tokenized_training1, tokenized_training2, train_examples):\n",
        "  train_index = random.sample(range(0, len(train_df['label'].values)), train_examples)\n",
        "  train_tokenized_training1 = []\n",
        "  train_tokenized_training2 = []\n",
        "  train_labels = []\n",
        "\n",
        "  eval_tokenized_training1 = []\n",
        "  eval_tokenized_training2 = []\n",
        "  eval_labels = []\n",
        "\n",
        "  for i in range(len(train_df['label'].values)):\n",
        "    if i in train_index:\n",
        "      train_tokenized_training1.append(tokenized_training1[i])\n",
        "      train_tokenized_training2.append(tokenized_training2[i])\n",
        "      train_labels.append(train_df['label'].values[i])\n",
        "    else:\n",
        "      eval_tokenized_training1.append(tokenized_training1[i])\n",
        "      eval_tokenized_training2.append(tokenized_training2[i])\n",
        "      eval_labels.append(train_df['label'].values[i])\n",
        "  \n",
        "  return train_tokenized_training1, train_tokenized_training2, train_labels, eval_tokenized_training1, eval_tokenized_training2, eval_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEVd27eSPcM9"
      },
      "source": [
        "# Returns couple of sentences with both ordering (sentence1, sentence2) and (sentence2, sentence1) with the correct label\n",
        "def get_dataset_and_inverse(labels, tokenized_training1, tokenized_training2):\n",
        "  inverse_labels = []\n",
        "  for label in labels:\n",
        "    if label == 0:\n",
        "      inverse_labels.append(1)\n",
        "    elif label == 1:\n",
        "      inverse_labels.append(0)\n",
        "  total_labels = [*labels, *inverse_labels]\n",
        "  left_tokenized = [*tokenized_training1, *tokenized_training2]\n",
        "  right_tokenized = [*tokenized_training2, *tokenized_training1]\n",
        "  return total_labels, left_tokenized, right_tokenized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h2J_mRkYdXq"
      },
      "source": [
        "# We set our training data and test data\n",
        "\n",
        "training_data1 = train_df['original1'].values\n",
        "training_edit1 = train_df['edit1'].values\n",
        "val_data1 = val_df['original1'].values\n",
        "val_edit1 = val_df['edit1'].values\n",
        "test_data1 = test_df['original1'].values\n",
        "test_edit1 = test_df['edit1'].values\n",
        "\n",
        "training_data2 = train_df['original2'].values\n",
        "training_edit2 = train_df['edit2'].values\n",
        "val_data2 = val_df['original2'].values\n",
        "val_edit2 = val_df['edit2'].values\n",
        "test_data2 = test_df['original2'].values\n",
        "test_edit2 = test_df['edit2'].values\n",
        "\n",
        "\n",
        "# We replace with the editted word\n",
        "edit_training_data1 = replace_word_dataset(training_data1, training_edit1)\n",
        "edit_val_data1 = replace_word_dataset(val_data1, val_edit1)\n",
        "edit_test_data1 = replace_word_dataset(test_data1, test_edit1)\n",
        "edit_training_data2 = replace_word_dataset(training_data2, training_edit2)\n",
        "edit_val_data2 = replace_word_dataset(val_data2, val_edit2)\n",
        "edit_test_data2 = replace_word_dataset(test_data2, test_edit2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbVNuO7wEw9P",
        "outputId": "d563237c-446d-4512-8b5c-ad190a1083e1"
      },
      "source": [
        "# Tokenize dataset with BERT tokenizer\n",
        "tokenized_training1 = tokenized_dataset(edit_training_data1)\n",
        "tokenized_training2 = tokenized_dataset(edit_training_data2)\n",
        "\n",
        "# Splint dataset into train and eval\n",
        "nb_train_examples = round(len(train_df['label'].values)*train_proportion)\n",
        "train_tokenized_training1, train_tokenized_training2, train_labels, eval_tokenized_training1, eval_tokenized_training2, eval_labels = get_train_and_eval(tokenized_training1, tokenized_training2, nb_train_examples)\n",
        "\n",
        "# Get datasets in both orders\n",
        "train_total_labels, train_left_tokenized, train_right_tokenized = get_dataset_and_inverse(train_labels, train_tokenized_training1, train_tokenized_training2)\n",
        "eval_total_labels, eval_left_tokenized, eval_right_tokenized = get_dataset_and_inverse(eval_labels, eval_tokenized_training1, eval_tokenized_training2)\n",
        "\n",
        "# Convert set to Dataset\n",
        "train_dataset = Task2Dataset_BERT(train_left_tokenized, train_right_tokenized, train_total_labels)\n",
        "dev_dataset = Task2Dataset_BERT(eval_left_tokenized, eval_right_tokenized, eval_total_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PZYmvfZd-kM",
        "outputId": "13d6f020-df70-40df-9910-691471d7ef4e"
      },
      "source": [
        "# Tokenize dataset with BERT tokenizer\n",
        "tokenized_val1 = tokenized_dataset(edit_val_data1)\n",
        "tokenized_val2 = tokenized_dataset(edit_val_data2)\n",
        "\n",
        "# Get datasets in both orders\n",
        "val_total_labels, val_left_tokenized, val_right_tokenized = get_dataset_and_inverse(val_df['label'].values, tokenized_val1, tokenized_val2)\n",
        "\n",
        "# Convert set to Dataset\n",
        "val_dataset = Task2Dataset_BERT(val_left_tokenized, val_right_tokenized, val_total_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "fi8lKpyKfYsQ",
        "outputId": "7391566e-a6ac-4a29-e185-2fea6d41384f"
      },
      "source": [
        "# These hyperparameter values are those recommended\n",
        "epochs = 10\n",
        "\n",
        "config = {\n",
        "    \"batch_size\": [32, 64],\n",
        "    \"lr\": [1e-5, 2e-5, 5e-5]\n",
        "}\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "def hyperparameter_tuning(config):\n",
        "\n",
        "    for batch_size in config['batch_size']:\n",
        "      for lr in config['lr']:\n",
        "        print('Trying with batch size = ' + str(batch_size) + ' and learning rate = ' + str(lr))\n",
        "\n",
        "        model = ColBERT.from_pretrained(bert_model)\n",
        "        model.to(device)\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "        dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=batch_size)\n",
        "\n",
        "        train(train_loader, dev_loader, model, epochs, optimizer)\n",
        "\n",
        "    \n",
        "    print(\"Hyperparameter tuning done\")\n",
        "    return\n",
        "  \n",
        "hyperparameter_tuning(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trying with batch size = 32 and learning rate = 1e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['final_layer.1.weight', 'final_layer.1.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-afa971678f0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-afa971678f0f>\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdev_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-0aa9db121fd2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, dev_iter, model, number_epoch, optimizer)\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mattention_mask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m               \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-d8fab7fd070b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids1, attention_mask1, input_ids2, attention_mask2)\u001b[0m\n\u001b[1;32m     25\u001b[0m     outputs2 = self.bert(\n\u001b[1;32m     26\u001b[0m         \u001b[0minput_ids2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m         )\n\u001b[1;32m    978\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    572\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 )\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         )\n\u001b[1;32m    498\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m     \u001b[0;31m# inspect.signature exist since python 3.5 and is a python method -> no problem with backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m     \u001b[0mnum_args_in_forward_chunk_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m     assert num_args_in_forward_chunk_fn == len(\n\u001b[1;32m   1766\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2831\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2832\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0;32m-> 2833\u001b[0;31m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[1;32m   2834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2835\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2215\u001b[0m             \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m             \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m             sigcls=sigcls)\n\u001b[0m\u001b[1;32m   2218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2282\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0;32m-> 2154\u001b[0;31m                                     kind=_POSITIONAL_OR_KEYWORD))\n\u001b[0m\u001b[1;32m   2155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m     \u001b[0;31m# ... w/ defaults.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \"\"\"\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simple value lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;31m# otherwise, functional API: we're creating a new Enum type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/enum.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# without calling this method; this method is called by the metaclass'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# __call__ (i.e. Color(3) ), and by pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0;31m# For lookups like Color(Color.RED)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xIy9baag6lb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "7e3c29d2-8b3b-46c2-d006-8f9e32833cde"
      },
      "source": [
        "# We initialise BERT model for classification\n",
        "model = ColBERT.from_pretrained(bert_model)\n",
        "model.to(device)\n",
        "print(\"Model initialised.\")\n",
        "\n",
        "# Train on the whole dataset to have the best possible model\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-5\n",
        "epochs = 3\n",
        "\n",
        "# Tokenize dataset with BERT tokenizer\n",
        "tokenized_training1 = tokenized_dataset(edit_training_data1)\n",
        "tokenized_training2 = tokenized_dataset(edit_training_data2)\n",
        "\n",
        "# Get datasets in both orders\n",
        "train_total_labels, train_left_tokenized, train_right_tokenized = get_dataset_and_inverse(train_df['label'].values, tokenized_training1, tokenized_training2)\n",
        "\n",
        "# Convert set to Dataset\n",
        "train_dataset = Task2Dataset_BERT(train_left_tokenized, train_right_tokenized, train_total_labels)\n",
        "\n",
        "# Create Datatloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(\"Dataloaders created.\")\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Train\n",
        "train(train_loader, val_loader, model, epochs, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing ColBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing ColBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ColBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ColBERT were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['final_layer.1.weight', 'final_layer.1.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n",
            "Dataloaders created.\n",
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-676a6eea4912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-0aa9db121fd2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, dev_iter, model, number_epoch, optimizer)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AlbtrEQrCv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d97133-9b0d-48b7-90d1-45956ae281e5"
      },
      "source": [
        "tokenized_test1 = tokenized_dataset(edit_test_data1)\n",
        "tokenized_test2 = tokenized_dataset(edit_test_data2)\n",
        "fake_labels = [1] * len(tokenized_test1)\n",
        "\n",
        "test_dataset = Task2Dataset_BERT(tokenized_test1, tokenized_test2, fake_labels)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "def create_submission_file(test_loader):\n",
        "    # Get results\n",
        "    results  = np.array([])\n",
        "    for batch in test_loader:\n",
        "      input_ids1, attention_mask1, input_ids2, attention_mask2, target = batch\n",
        "      input_ids1, attention_mask1, input_ids2, attention_mask2, target = input_ids1.to(device), attention_mask1.to(device), input_ids2.to(device), attention_mask2.to(device), target.to(device)\n",
        "      input_ids1 = input_ids1.squeeze(1)\n",
        "      attention_mask1 = attention_mask1.squeeze(1)\n",
        "      input_ids2 = input_ids2.squeeze(1)\n",
        "      attention_mask2 = attention_mask2.squeeze(1)\n",
        "      batch_results = model(input_ids1, attention_mask1, input_ids2, attention_mask2).squeeze(1)\n",
        "      batch_results = np.around(batch_results.detach().cpu().numpy())\n",
        "      results = np.concatenate((results, batch_results))\n",
        "\n",
        "    #Create data\n",
        "    ids = test_df['id']\n",
        "    results = results + 1\n",
        "    results = results.astype(int)\n",
        "\n",
        "    data = {'id': ids, \n",
        "            'pred': results}\n",
        "    df = pd.DataFrame(data, columns=['id', 'pred'])\n",
        "\n",
        "    #Export data to csv\n",
        "    compression_opts = dict(method='zip',archive_name='task-2-output.csv') \n",
        "    df.to_csv('task-2-output.zip', index=False, compression=compression_opts)\n",
        "    return\n",
        "\n",
        "create_submission_file(test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oatMnFeB0Bln"
      },
      "source": [
        "#### Approach 2: No pre-trained representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2LBdiP5I7mn"
      },
      "source": [
        "# We set our training data and test data\n",
        "training_data1 = train_df['original1'].values\n",
        "training_edit1 = train_df['edit1'].values\n",
        "val_data1 = val_df['original1'].values\n",
        "val_edit1 = val_df['edit1'].values\n",
        "test_data1 = test_df['original1'].values\n",
        "test_edit1 = test_df['edit1'].values\n",
        "\n",
        "training_data2 = train_df['original2'].values\n",
        "training_edit2 = train_df['edit2'].values\n",
        "val_data2 = val_df['original2'].values\n",
        "val_edit2 = val_df['edit2'].values\n",
        "test_data2 = test_df['original2'].values\n",
        "test_edit2 = test_df['edit2'].values\n",
        "\n",
        "# We replace with the editted word\n",
        "edit_train1 = replace_word_dataset(training_data1, training_edit1)\n",
        "edit_val1 = replace_word_dataset(val_data1, val_edit1)\n",
        "edit_test1 = replace_word_dataset(test_data1, test_edit1)\n",
        "edit_train2 = replace_word_dataset(training_data2, training_edit2)\n",
        "edit_val2 = replace_word_dataset(val_data2, val_edit2)\n",
        "edit_test2 = replace_word_dataset(test_data2, test_edit2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-MO1xrjI8aU"
      },
      "source": [
        "# We create a corpus with all the edited sentences and without duplicates\n",
        "corpus = [*edit_train1, *edit_val1, *edit_test1, *edit_train2, *edit_val2, *edit_test2]\n",
        "corpus_without_duplicates = list(dict.fromkeys(corpus))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEfdGne-g6Dt"
      },
      "source": [
        "class Vocabulary(object):\n",
        "  \"\"\"Data structure representing the vocabulary of a corpus.\"\"\"\n",
        "  def __init__(self, window_size=2):\n",
        "    self.window_size = window_size\n",
        "\n",
        "    # Mapping from tokens to integers\n",
        "    self._word2idx = {}\n",
        "\n",
        "    # Reverse-mapping from integers to tokens\n",
        "    self.idx2word = []\n",
        "\n",
        "    # Pairs of words according to the window size\n",
        "    self.idx_pairs = []\n",
        "\n",
        "    # 0-padding token\n",
        "    # TO: keep or remove\n",
        "    self.add_word('<pad>')\n",
        "    # sentence start\n",
        "    # TO: keep or remove\n",
        "    self.add_word('<s>')\n",
        "    # sentence end\n",
        "    # TO: keep or remove\n",
        "    self.add_word('</s>')\n",
        "    # Unknown words\n",
        "    self.add_word('<unk>')\n",
        "    # add separator\n",
        "    self.add_word('<sep>')\n",
        "\n",
        "    self._unk_idx = self._word2idx['<unk>']\n",
        "\n",
        "  def word2idx(self, word):\n",
        "    \"\"\"Returns the integer ID of the word or <unk> if not found.\"\"\"\n",
        "    return self._word2idx.get(word, self._unk_idx)\n",
        "\n",
        "  def add_word(self, word):\n",
        "    \"\"\"Adds the `word` into the vocabulary.\"\"\"\n",
        "    if word not in self._word2idx:\n",
        "      self.idx2word.append(word)\n",
        "      self._word2idx[word] = len(self.idx2word) - 1\n",
        "\n",
        "  def build_from_file(self, corpus):\n",
        "    \"\"\"Builds a vocabulary from a given corpus file.\"\"\"\n",
        "    for sentence in corpus:\n",
        "      words = sentence.strip().split()\n",
        "      for word in words:\n",
        "        self.add_word(word)\n",
        "  \n",
        "  def get_idx_pairs(self, sentence, id):\n",
        "    idx_pairs = []\n",
        "    for w in range(-self.window_size, self.window_size+1):\n",
        "      id_context_word = id + w\n",
        "      if w < 0 or w >= len(sentence) or w == id:\n",
        "        continue\n",
        "      idx_pairs.append(self.convert_words_to_idxs([sentence[id], sentence[w]]))\n",
        "    return idx_pairs\n",
        "  \n",
        "  def build_idx_pairs(self, corpus):\n",
        "    \"\"\"Builds the pair of idx from a given corpus file.\"\"\"\n",
        "    for sentence in corpus:\n",
        "      words = sentence.strip().split()\n",
        "      for id in range(0, len(words)):\n",
        "        new_idx_pairs = self.get_idx_pairs(words, id)\n",
        "      self.idx_pairs += new_idx_pairs\n",
        "    return\n",
        "\n",
        "  def convert_idxs_to_words(self, idxs):\n",
        "    \"\"\"Converts a list of indices to words.\"\"\"\n",
        "    return ' '.join(self.idx2word[idx] for idx in idxs)\n",
        "\n",
        "  def convert_words_to_idxs(self, words):\n",
        "    \"\"\"Converts a list of words to a list of indices.\"\"\"\n",
        "    return [self.word2idx(w) for w in words]\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"Returns the size of the vocabulary.\"\"\"\n",
        "    return len(self.idx2word)\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return \"Vocabulary with {} items\".format(self.__len__())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzRw18yOg6GR"
      },
      "source": [
        "# Create vocabulary base on our corpus\n",
        "vocab = Vocabulary(window_size=2)\n",
        "vocab.build_from_file(corpus_without_duplicates)\n",
        "vocab.build_idx_pairs(corpus_without_duplicates)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9XtfdMa6YDN"
      },
      "source": [
        "# Parameters\n",
        "vocabulary_size = len(vocab)\n",
        "embedding_dims = 10\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "nb_words_to_sample = 5\n",
        "\n",
        "# Matrices\n",
        "W1 = torch.randn(embedding_dims, vocabulary_size, requires_grad=True, device=device)\n",
        "W2 = torch.randn(embedding_dims, vocabulary_size, requires_grad=True, device=device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "y4HbyWVO7KGb",
        "outputId": "b34d4e1f-6c0e-4e30-85cf-d05290e36c97"
      },
      "source": [
        "# Compute word embeddings with negative sampling\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0\n",
        "  percentage = 0\n",
        "  count = 0\n",
        "  for data, target in vocab.idx_pairs:\n",
        "\n",
        "      count += 1\n",
        "      if round(count/len(vocab.idx_pairs)*100) > percentage:\n",
        "        percentage = round(count/len(vocab.idx_pairs)*100)\n",
        "        print(str(percentage) + '% of epoch ' + str(epoch))\n",
        "        \n",
        "      x_var = Variable(one_hot_encoder(data)).float().to(device)\n",
        "      y_pos_var = Variable(one_hot_encoder(target)).float().to(device)\n",
        "\n",
        "      neg_sample = np.random.choice(list(range(vocabulary_size)), size=(nb_words_to_sample))\n",
        "      y_neg = []\n",
        "      for id_neg_sample in neg_sample:\n",
        "        word = vocab.idx2word[id_neg_sample]\n",
        "        y_neg.append(one_hot_encoder(word).numpy())\n",
        "      y_neg = torch.tensor(y_neg)\n",
        "      y_neg_var = Variable(y_neg).float().to(device)\n",
        "\n",
        "      x_emb = torch.matmul(W1, x_var) \n",
        "      y_pos_emb = torch.matmul(W2, y_pos_var)\n",
        "      y_neg_emb = torch.matmul(W2, y_neg_var.transpose(0,1))\n",
        "\n",
        "      # get positive sample score\n",
        "      pos_loss = F.logsigmoid(torch.matmul(x_emb, y_pos_emb))\n",
        "        \n",
        "      # get negsample score\n",
        "      neg_loss = F.logsigmoid(-1 * torch.matmul(x_emb, y_neg_emb))\n",
        "      exp_neg_loss = torch.mean(neg_loss)\n",
        "        \n",
        "      loss = - (pos_loss + nb_words_to_sample * exp_neg_loss)\n",
        "      epoch_loss += loss.item()\n",
        "        \n",
        "      # propagate the error\n",
        "      loss.backward()\n",
        "        \n",
        "      # gradient descent\n",
        "      W1.data -= learning_rate * W1.grad.data\n",
        "      W2.data -= learning_rate * W2.grad.data\n",
        "\n",
        "      # zero out gradient accumulation\n",
        "      W1.grad.data.zero_()\n",
        "      W2.grad.data.zero_()\n",
        "        \n",
        "  print(f'Loss at epo {epoch}: {epoch_loss/len(vocab.idx_pairs)}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1% of epoch 0\n",
            "2% of epoch 0\n",
            "3% of epoch 0\n",
            "4% of epoch 0\n",
            "5% of epoch 0\n",
            "6% of epoch 0\n",
            "7% of epoch 0\n",
            "8% of epoch 0\n",
            "9% of epoch 0\n",
            "10% of epoch 0\n",
            "11% of epoch 0\n",
            "12% of epoch 0\n",
            "13% of epoch 0\n",
            "14% of epoch 0\n",
            "15% of epoch 0\n",
            "16% of epoch 0\n",
            "17% of epoch 0\n",
            "18% of epoch 0\n",
            "19% of epoch 0\n",
            "20% of epoch 0\n",
            "21% of epoch 0\n",
            "22% of epoch 0\n",
            "23% of epoch 0\n",
            "24% of epoch 0\n",
            "25% of epoch 0\n",
            "26% of epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-ba4b159f969a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_neg_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0my_neg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0my_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0my_neg_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ZolbX8Jh27"
      },
      "source": [
        "# Get a clean dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwLAaqMbK1Wg"
      },
      "source": [
        "def concat_datasets(dataset1, dataset2):\n",
        "  concat_dataset = []\n",
        "  for i in range (len(dataset1)):\n",
        "    new_sentence = dataset1[i] + \" <sep> \" + dataset2[i]\n",
        "    # concat_dataset.append(new_sentence)\n",
        "    concat_dataset.append(new_sentence.lower())\n",
        "  return pd.Series(concat_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c7h1AugMAJT"
      },
      "source": [
        "def tokenized_corpus(concat_dataset):\n",
        "  tokenized_corpus = []\n",
        "  for sentence in concat_dataset:\n",
        "    tokenized_sentence = []\n",
        "    for token in sentence.split(' '):\n",
        "      tokenized_sentence.append(token)\n",
        "    tokenized_corpus.append(tokenized_sentence)\n",
        "  return tokenized_corpus"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qem5ut2Mpv99"
      },
      "source": [
        "def get_vectorized_seq(tokenized_data):\n",
        "  vectorized_seqs = []\n",
        "  for seq in tokenized_data:\n",
        "    # remove_invalid_headline\n",
        "    if len(seq) <= 3: continue\n",
        "    vectorized_seq = []\n",
        "    for tok in seq:\n",
        "        vectorized_seq.append(vocab.word2idx(tok))\n",
        "    vectorized_seqs.append(vectorized_seq)\n",
        "  return vectorized_seqs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeX5gelUpd4b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJhIlvUExT1B",
        "outputId": "c0afef2f-3f11-4a94-80d9-8377d7f5b5af"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STHktcOtzfR_"
      },
      "source": [
        "def tokenized_corpus_preprocess(corpus, isTrain=True):\n",
        "  tokenized_corpus_PR = []  # PR = punctuation removed\n",
        "  re_punctuation_string = '[\\s,/.\\'\\\"\\[\\]|#~]'\n",
        "  if isTrain:\n",
        "    for sentence in corpus:\n",
        "      tokenized_sentence_PR = re.split(re_punctuation_string, sentence)\n",
        "      tokenized_sentence_PR = list(filter(None, tokenized_sentence_PR)) # remove empty\n",
        "      tokenized_sentence_PR = list(\n",
        "          filter(lambda x: [word for word in x if word not in stop_words],\n",
        "                tokenized_sentence_PR))\n",
        "      tokenized_corpus_PR.append(tokenized_sentence_PR)\n",
        "  else:\n",
        "    tokenized_corpus_PR = tokenized_corpus(corpus)\n",
        "  \n",
        "  return tokenized_corpus_PR"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l34OBwLipiEI"
      },
      "source": [
        "class Task2Dataset_BiLSTM(Dataset):\n",
        "\n",
        "    def __init__(self, train1_data, train2_data, labels):\n",
        "        self.x1_train = train1_data\n",
        "        self.x2_train = train2_data\n",
        "        self.y_train = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_train)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.x1_train[item], self.x2_train[item], self.y_train[item]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khEdFT3CqrG2"
      },
      "source": [
        "# Get tokenized datasets\n",
        "\n",
        "tokenized_train1 = tokenized_corpus(edit_train1)\n",
        "tokenized_train2 = tokenized_corpus(edit_train2)\n",
        "tokenized_val1 = tokenized_corpus(edit_val1)\n",
        "tokenized_val2 = tokenized_corpus(edit_val2)\n",
        "tokenized_test1 = tokenized_corpus(edit_test1)\n",
        "tokenized_test2 = tokenized_corpus(edit_test2)\n",
        "# with preprocessing\n",
        "#tokenized_train1 = tokenized_corpus_preprocess(edit_train1)\n",
        "#tokenized_train2 = tokenized_corpus_preprocess(edit_train2)\n",
        "#tokenized_dev1 = tokenized_corpus_preprocess(edit_val1)\n",
        "#tokenized_dev2 = tokenized_corpus_preprocess(edit_val2)\n",
        "\n",
        "# Get vectorized seq\n",
        "vectorized_train1 = get_vectorized_seq(tokenized_train1)\n",
        "vectorized_train2 = get_vectorized_seq(tokenized_train2)\n",
        "vectorized_dev1 = get_vectorized_seq(tokenized_val1)\n",
        "vectorized_dev2 = get_vectorized_seq(tokenized_val2)\n",
        "vectorized_test1 = get_vectorized_seq(tokenized_test1)\n",
        "vectorized_test2 = get_vectorized_seq(tokenized_test2)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajqwMTNEE09B"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "class BiLSTM_Attention(torch.nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, lstm_layers, vocab_size, batch_size):\n",
        "\n",
        "        super(BiLSTM_Attention, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.use_gpu = torch.cuda.is_available()\n",
        "        \n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        #self.word_embeddings.weight = nn.Parameter(opt.embeddings,requires_grad=opt.embedding_training)\n",
        "        #self.word_embeddings.weight.data.copy_(torch.from_numpy(opt.embeddings))\n",
        "  \n",
        "        self.num_layers = lstm_layers\n",
        "        self.label_size = 2\n",
        "        self.num_merging_layers = 3\n",
        "        self.dropout = 0.2\n",
        "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim // 2, batch_first=True,\n",
        "                              num_layers=self.num_layers, dropout=self.dropout, bidirectional=True)\n",
        "        self.hidden2label = nn.Linear(hidden_dim * self.num_merging_layers, self.label_size)\n",
        "        #self.hidden2label = nn.Linear(hidden_dim * self.num_merging_layers, 1)\n",
        "        self.hidden = self.init_hidden() \n",
        "        self.attn_fc = torch.nn.Linear(embedding_dim, 1)\n",
        "\n",
        "    def init_hidden(self,batch_size=None):\n",
        "        if batch_size is None:\n",
        "            batch_size= self.batch_size\n",
        "        if self.use_gpu:\n",
        "            h0 = Variable(torch.zeros(2*self.num_layers, batch_size, self.hidden_dim // 2).cuda())\n",
        "            c0 = Variable(torch.zeros(2*self.num_layers, batch_size, self.hidden_dim // 2).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(2*self.num_layers, batch_size, self.hidden_dim // 2))\n",
        "            c0 = Variable(torch.zeros(2*self.num_layers, batch_size, self.hidden_dim // 2))\n",
        "        return (h0, c0)\n",
        "\n",
        "    def attention(self, rnn_out, state):\n",
        "        merged_state = torch.cat([s for s in state], 1)\n",
        "        merged_state = merged_state.squeeze(0).unsqueeze(2)\n",
        "        # (batch, seq_len, cell_size) * (batch, cell_size, 1) = (batch, seq_len, 1)\n",
        "        weights = torch.bmm(rnn_out, merged_state)\n",
        "        weights = nn.functional.softmax(weights.squeeze(2)).unsqueeze(2)\n",
        "        # (batch, cell_size, seq_len) * (batch, seq_len, 1) = (batch, cell_size, 1)\n",
        "        attn_out = torch.bmm(torch.transpose(rnn_out, 1, 2), weights).squeeze(2)\n",
        "        return attn_out\n",
        "\n",
        "    def forward(self, X1, X2):\n",
        "        embedded1 = self.word_embeddings(X1)\n",
        "        hidden1= self.init_hidden(X1.size()[0])\n",
        "        rnn_out1, hidden1 = self.bilstm(embedded1, hidden1)\n",
        "        h_n1, _ = hidden1\n",
        "        attn_out1 = self.attention(rnn_out1, h_n1)\n",
        "\n",
        "        embedded2 = self.word_embeddings(X2)\n",
        "        hidden2= self.init_hidden(X2.size()[0])\n",
        "        rnn_out2, hidden2 = self.bilstm(embedded2, hidden2)\n",
        "        h_n2, _ = hidden2\n",
        "        attn_out2 = self.attention(rnn_out2, h_n2)\n",
        "\n",
        "        abs_out = torch.abs(attn_out1 - attn_out2)\n",
        "        attn_merged = torch.cat([attn_out1, attn_out2, abs_out], 1)\n",
        "        logits = self.hidden2label(attn_merged)\n",
        "        return logits"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ytuih4UuuU3"
      },
      "source": [
        "# We define our training loop\n",
        "def train_log(train_iter, dev_iter, model, number_epoch, optimizer):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Training model.\")\n",
        "\n",
        "    log = {'epoch_acc':[], 'valid_acc':[]}\n",
        "\n",
        "    for epoch in range(1, number_epoch+1):\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "        epoch_correct = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "        for batch in train_iter:\n",
        "\n",
        "            if model.__class__.__name__ == 'ColBERT':\n",
        "              # predictions if model is BERT\n",
        "              input_ids1, attention_mask1, input_ids2, attention_mask2, target = batch\n",
        "              target =  target.type(torch.FloatTensor)\n",
        "              input_ids1, attention_mask1, input_ids2, attention_mask2, target = input_ids1.to(device), attention_mask1.to(device), input_ids2.to(device), attention_mask2.to(device), target.to(device)\n",
        "              input_ids1 = input_ids1.squeeze(1)\n",
        "              attention_mask1 = attention_mask1.squeeze(1)\n",
        "              input_ids2 = input_ids2.squeeze(1)\n",
        "              attention_mask2 = attention_mask2.squeeze(1)\n",
        "\n",
        "              predictions = model(input_ids1, attention_mask1, input_ids2, attention_mask2).squeeze(1)\n",
        "\n",
        "            elif model.__class__.__name__ == 'BiLSTM_Attention':\n",
        "              X1, X2, target = batch\n",
        "              #target = target.type(torch.FloatTensor)\n",
        "              X1, X2, target = X1.to(device), X2.to(device), target.to(device)\n",
        "              model.batch_size = target.shape[0]\n",
        "              predictions = model(X1, X2).squeeze(1)\n",
        "          \n",
        "            else:\n",
        "              # predictions if model is not BERT\n",
        "              feature, target = batch\n",
        "              feature, target = feature.to(device), target.to(device)\n",
        "              # for RNN\n",
        "              model.batch_size = target.shape[0]\n",
        "              model.hidden = model.init_hidden()\n",
        "              predictions = model(feature).squeeze(1)\n",
        "\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(predictions, target)\n",
        "            \n",
        "            if model.__class__.__name__ == 'ColBERT':\n",
        "              correct, __ = model_performance(np.around(predictions.detach().cpu().numpy()), target.detach().cpu().numpy())\n",
        "            else:\n",
        "              correct, __ = model_performance(np.argmax(predictions.detach().cpu().numpy(), axis=1), target.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_correct += correct\n",
        "\n",
        "        valid_loss, valid_acc, __, __ = eval(dev_iter, model)\n",
        "\n",
        "        epoch_loss, epoch_acc = epoch_loss / no_observations, epoch_correct / no_observations\n",
        "        \n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train Accuracy: {epoch_acc:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. Accuracy: {valid_acc:.2f} |')\n",
        "\n",
        "        log['epoch_acc'].append(epoch_acc)\n",
        "        log['valid_acc'].append(valid_acc)\n",
        "    return log"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f22VNwCtUHEs"
      },
      "source": [
        "################### added T-C ###################\n",
        "# hyperparameter tuning\n",
        "import os\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "\n",
        "# We define our training loop\n",
        "def train_tune(config, train_dataset=None, dev_dataset=None, num_epochs=20, vocab_size=33234, checkpoint_dir=None, data_dir=None):\n",
        "    \"\"\"\n",
        "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
        "    \"\"\"\n",
        "    LSTM_LAYERS = 1\n",
        "    model = BiLSTM_Attention(config['embedding_dim'], config['hidden_dim'],\n",
        "                             LSTM_LAYERS, vocab_size, config['batch_size'])\n",
        "\n",
        "    device = \"cpu\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda:0\"\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            model = nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"])\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    loss_fn = loss_fn.to(device)\n",
        "    if checkpoint_dir:\n",
        "        checkpoint = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "        model_state, optimizer_state = torch.load(checkpoint)\n",
        "        model.load_state_dict(model_state)\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=config['batch_size'], collate_fn=collate_fn_padd)\n",
        "    dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=config['batch_size'], collate_fn=collate_fn_padd)\n",
        "    print(\"Training model.\")\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        epoch_loss = 0\n",
        "        epoch_correct = 0\n",
        "        no_observations = 0  # Observations used for training so far\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            ############################# added T-C #############################\n",
        "            X1, X2, target = batch\n",
        "            X1, X2, target = X1.to(device), X2.to(device), target.to(device)\n",
        "            model.batch_size = target.shape[0]\n",
        "            predictions = model(X1, X2).squeeze(1)\n",
        "            ############################# added T-C #############################\n",
        "            no_observations = no_observations + target.shape[0]\n",
        "            # for RNN:\n",
        "            # model.batch_size = target.shape[0]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = loss_fn(predictions, target)\n",
        "\n",
        "            correct, __ = model_performance(np.argmax(predictions.detach().cpu().numpy(), axis=1), target.detach().cpu().numpy())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()*target.shape[0]\n",
        "            epoch_correct += correct\n",
        "            #if i % 1000 == 999:  # print every 2000 mini-batches\n",
        "            #  print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
        "            #                                    epoch_loss / no_observations))\n",
        "\n",
        "        valid_loss, valid_acc, __, __ = eval(dev_loader, model)\n",
        "        #with tune.checkpoint_dir(step=epoch) as checkpoint_dir:\n",
        "        #    path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "        #    torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
        "\n",
        "        #tune.report(loss=valid_loss, accuracy=valid_acc)\n",
        "\n",
        "        epoch_loss, epoch_acc = epoch_loss / no_observations, epoch_correct / no_observations\n",
        "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train Accuracy: {epoch_acc:.2f} | \\\n",
        "        Val. Loss: {valid_loss:.2f} | Val. Accuracy: {valid_acc:.2f} |')\n",
        "\n",
        "\n",
        "# debug\n",
        "\n",
        "\n",
        "config = {\n",
        "          \"lr\": loguniform.rvs(4e-4, 1e-3),\n",
        "          \"batch_size\": int(np.random.choice([8, 16, 32, 64, 128])),\n",
        "          \"hidden_dim\": np.random.randint(10, 100),\n",
        "          'embedding_dim': np.random.randint(10, 100)\n",
        "}\n",
        "print(config)\n",
        "train_tune(config, train_dataset=train_dataset, dev_dataset=dev_dataset, num_epochs=20, vocab_size=INPUT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0muyf3RWXuK4"
      },
      "source": [
        "\"\"\" log of hyperparameter search results\n",
        "{'lr': 1.1268996026163215e-05, 'batch_size': 128, 'hidden_dim': 38, 'embedding_dim': 17}\n",
        "val_acc == 0.51\n",
        "{'lr': 1.3969795891901723e-05, 'batch_size': 32, 'hidden_dim': 54, 'embedding_dim': 80}\n",
        "val_acc = 0.51\n",
        "{'lr': 0.0001673823430001329, 'batch_size': 32, 'hidden_dim': 62, 'embedding_dim': 17}\n",
        "val_acc == 0.51\n",
        "{'lr': 0.00017990056847114912, 'batch_size': 64, 'hidden_dim': 24, 'embedding_dim': 88}\n",
        "val_acc == 0.53\n",
        "{'lr': 0.0002036080914977387, 'batch_size': 64, 'hidden_dim': 88, 'embedding_dim': 79}\n",
        "val_acc == 0.53\n",
        "{'lr': 0.0002608033772419257, 'batch_size': 128, 'hidden_dim': 10, 'embedding_dim': 63}\n",
        "val_acc == 0.51\n",
        "{'lr': 0.000799899263008792, 'batch_size': 64, 'hidden_dim': 52, 'embedding_dim': 58}\n",
        "val_acc == 0.51\n",
        "{'lr': 0.0009554815939036779, 'batch_size': 8, 'hidden_dim': 34, 'embedding_dim': 29}\n",
        "val_acc == 0.53\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ8vsNg0ZziH",
        "outputId": "f4a88f98-5301-4564-c059-711ab20d362b"
      },
      "source": [
        "# BEST RESULT\n",
        "config = {\n",
        "          \"lr\": loguniform.rvs(1e-4, 1e-3),\n",
        "          \"batch_size\": int(np.random.choice([8, 16, 32, 64, 128])),\n",
        "          \"hidden_dim\": np.random.randint(10, 100),\n",
        "          'embedding_dim': np.random.randint(10, 100)\n",
        "}\n",
        "print(config)\n",
        "train_tune(config, train_dataset=train_dataset, dev_dataset=dev_dataset, num_epochs=20, vocab_size=INPUT_DIM)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.000708766153261764, 'batch_size': 32, 'hidden_dim': 82, 'embedding_dim': 45}\n",
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.69 | Train Accuracy: 0.51 |         Val. Loss: 0.69 | Val. Accuracy: 0.51 |\n",
            "| Epoch: 02 | Train Loss: 0.69 | Train Accuracy: 0.54 |         Val. Loss: 0.69 | Val. Accuracy: 0.51 |\n",
            "| Epoch: 03 | Train Loss: 0.67 | Train Accuracy: 0.59 |         Val. Loss: 0.70 | Val. Accuracy: 0.52 |\n",
            "| Epoch: 04 | Train Loss: 0.62 | Train Accuracy: 0.66 |         Val. Loss: 0.72 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 05 | Train Loss: 0.55 | Train Accuracy: 0.73 |         Val. Loss: 0.77 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 06 | Train Loss: 0.46 | Train Accuracy: 0.78 |         Val. Loss: 0.83 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 07 | Train Loss: 0.38 | Train Accuracy: 0.83 |         Val. Loss: 0.90 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 08 | Train Loss: 0.30 | Train Accuracy: 0.87 |         Val. Loss: 0.98 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 09 | Train Loss: 0.24 | Train Accuracy: 0.91 |         Val. Loss: 1.07 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 10 | Train Loss: 0.19 | Train Accuracy: 0.93 |         Val. Loss: 1.18 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 11 | Train Loss: 0.14 | Train Accuracy: 0.95 |         Val. Loss: 1.29 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 12 | Train Loss: 0.11 | Train Accuracy: 0.97 |         Val. Loss: 1.41 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 13 | Train Loss: 0.09 | Train Accuracy: 0.97 |         Val. Loss: 1.50 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 14 | Train Loss: 0.07 | Train Accuracy: 0.98 |         Val. Loss: 1.56 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 15 | Train Loss: 0.05 | Train Accuracy: 0.99 |         Val. Loss: 1.69 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 16 | Train Loss: 0.04 | Train Accuracy: 0.99 |         Val. Loss: 1.71 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 17 | Train Loss: 0.03 | Train Accuracy: 0.99 |         Val. Loss: 1.80 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 18 | Train Loss: 0.03 | Train Accuracy: 0.99 |         Val. Loss: 1.87 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 19 | Train Loss: 0.02 | Train Accuracy: 1.00 |         Val. Loss: 1.93 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 20 | Train Loss: 0.03 | Train Accuracy: 0.99 |         Val. Loss: 1.87 | Val. Accuracy: 0.53 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsVKQCbrafA7"
      },
      "source": [
        "# BEST RESULTS\n",
        "learning_rate = 0.000708766153261764\n",
        "BATCH_SIZE = 32\n",
        "EMBEDDING_DIM = 83\n",
        "HIDDEN_DIM = 46\n",
        "INPUT_DIM = vocabulary_size\n",
        "LSTM_LAYERS = 1"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fl0o7iIqEcD",
        "outputId": "235f594b-e0dd-420d-896e-4c67e8d232af"
      },
      "source": [
        "model = BiLSTM_Attention(EMBEDDING_DIM, HIDDEN_DIM, LSTM_LAYERS, INPUT_DIM, BATCH_SIZE)\n",
        "print(\"Model initialised.\")\n",
        "\n",
        "model.to(device)\n",
        "# We provide the model with our embeddings\n",
        "#model.embedding.weight.data.copy_(W1.transpose(0,1))\n",
        "\n",
        "# 'feature' is a list of lists, each containing embedding IDs for word tokens\n",
        "train_dataset = Task2Dataset_BiLSTM(vectorized_train1, vectorized_train2, train_df['label'].values)\n",
        "dev_dataset = Task2Dataset_BiLSTM(vectorized_dev1, vectorized_dev2, val_df['label'].values)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "print(\"Dataloaders created.\")\n",
        "\n",
        "#loss_fn = nn.BCELoss()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss_fn = loss_fn.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model initialised.\n",
            "Dataloaders created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUqWwomLsuYW",
        "outputId": "6dcfdb7a-cbcc-449b-9b40-e2fb35ad89fb"
      },
      "source": [
        "epochs = 50\n",
        "train(train_loader, dev_loader, model, epochs, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.54 | Train Accuracy: 0.77 |         Val. Loss: 1.34 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 02 | Train Loss: 0.52 | Train Accuracy: 0.77 |         Val. Loss: 1.35 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 03 | Train Loss: 0.50 | Train Accuracy: 0.78 |         Val. Loss: 1.34 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 04 | Train Loss: 0.49 | Train Accuracy: 0.79 |         Val. Loss: 1.38 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 05 | Train Loss: 0.46 | Train Accuracy: 0.80 |         Val. Loss: 1.42 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 06 | Train Loss: 0.46 | Train Accuracy: 0.80 |         Val. Loss: 1.47 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 07 | Train Loss: 0.44 | Train Accuracy: 0.81 |         Val. Loss: 1.47 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 08 | Train Loss: 0.42 | Train Accuracy: 0.82 |         Val. Loss: 1.50 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 09 | Train Loss: 0.42 | Train Accuracy: 0.83 |         Val. Loss: 1.54 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 10 | Train Loss: 0.39 | Train Accuracy: 0.83 |         Val. Loss: 1.59 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 11 | Train Loss: 0.38 | Train Accuracy: 0.84 |         Val. Loss: 1.60 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 12 | Train Loss: 0.37 | Train Accuracy: 0.85 |         Val. Loss: 1.65 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 13 | Train Loss: 0.36 | Train Accuracy: 0.85 |         Val. Loss: 1.73 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 14 | Train Loss: 0.34 | Train Accuracy: 0.86 |         Val. Loss: 1.73 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 15 | Train Loss: 0.33 | Train Accuracy: 0.86 |         Val. Loss: 1.75 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 16 | Train Loss: 0.32 | Train Accuracy: 0.86 |         Val. Loss: 1.79 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 17 | Train Loss: 0.31 | Train Accuracy: 0.87 |         Val. Loss: 1.80 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 18 | Train Loss: 0.31 | Train Accuracy: 0.87 |         Val. Loss: 1.88 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 19 | Train Loss: 0.30 | Train Accuracy: 0.88 |         Val. Loss: 1.88 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 20 | Train Loss: 0.28 | Train Accuracy: 0.89 |         Val. Loss: 1.89 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 21 | Train Loss: 0.27 | Train Accuracy: 0.89 |         Val. Loss: 1.96 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 22 | Train Loss: 0.26 | Train Accuracy: 0.89 |         Val. Loss: 2.02 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 23 | Train Loss: 0.25 | Train Accuracy: 0.90 |         Val. Loss: 1.98 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 24 | Train Loss: 0.27 | Train Accuracy: 0.89 |         Val. Loss: 2.03 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 25 | Train Loss: 0.25 | Train Accuracy: 0.90 |         Val. Loss: 1.99 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 26 | Train Loss: 0.24 | Train Accuracy: 0.90 |         Val. Loss: 2.11 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 27 | Train Loss: 0.22 | Train Accuracy: 0.91 |         Val. Loss: 2.17 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 28 | Train Loss: 0.21 | Train Accuracy: 0.91 |         Val. Loss: 2.21 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 29 | Train Loss: 0.24 | Train Accuracy: 0.91 |         Val. Loss: 2.20 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 30 | Train Loss: 0.21 | Train Accuracy: 0.91 |         Val. Loss: 2.21 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 31 | Train Loss: 0.21 | Train Accuracy: 0.92 |         Val. Loss: 2.22 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 32 | Train Loss: 0.22 | Train Accuracy: 0.91 |         Val. Loss: 2.32 | Val. Accuracy: 0.57 |\n",
            "| Epoch: 33 | Train Loss: 0.20 | Train Accuracy: 0.92 |         Val. Loss: 2.30 | Val. Accuracy: 0.57 |\n",
            "| Epoch: 34 | Train Loss: 0.18 | Train Accuracy: 0.93 |         Val. Loss: 2.33 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 35 | Train Loss: 0.18 | Train Accuracy: 0.93 |         Val. Loss: 2.39 | Val. Accuracy: 0.57 |\n",
            "| Epoch: 36 | Train Loss: 0.17 | Train Accuracy: 0.93 |         Val. Loss: 2.35 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 37 | Train Loss: 0.17 | Train Accuracy: 0.93 |         Val. Loss: 2.49 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 38 | Train Loss: 0.17 | Train Accuracy: 0.93 |         Val. Loss: 2.43 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 39 | Train Loss: 0.17 | Train Accuracy: 0.93 |         Val. Loss: 2.48 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 40 | Train Loss: 0.16 | Train Accuracy: 0.94 |         Val. Loss: 2.49 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 41 | Train Loss: 0.16 | Train Accuracy: 0.94 |         Val. Loss: 2.55 | Val. Accuracy: 0.55 |\n",
            "| Epoch: 42 | Train Loss: 0.17 | Train Accuracy: 0.94 |         Val. Loss: 2.59 | Val. Accuracy: 0.57 |\n",
            "| Epoch: 43 | Train Loss: 0.15 | Train Accuracy: 0.94 |         Val. Loss: 2.60 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 44 | Train Loss: 0.15 | Train Accuracy: 0.94 |         Val. Loss: 2.65 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 45 | Train Loss: 0.14 | Train Accuracy: 0.95 |         Val. Loss: 2.77 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 46 | Train Loss: 0.13 | Train Accuracy: 0.95 |         Val. Loss: 2.73 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 47 | Train Loss: 0.13 | Train Accuracy: 0.95 |         Val. Loss: 2.63 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 48 | Train Loss: 0.17 | Train Accuracy: 0.93 |         Val. Loss: 2.71 | Val. Accuracy: 0.52 |\n",
            "| Epoch: 49 | Train Loss: 0.14 | Train Accuracy: 0.95 |         Val. Loss: 2.68 | Val. Accuracy: 0.56 |\n",
            "| Epoch: 50 | Train Loss: 0.13 | Train Accuracy: 0.95 |         Val. Loss: 2.75 | Val. Accuracy: 0.56 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNqQsIASkAz0",
        "outputId": "fbdf6eec-a4bc-414c-eced-1128d83e0a24"
      },
      "source": [
        "epochs = 20\n",
        "log = train_log(train_loader, dev_loader, model, epochs, optimizer)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.69 | Train Accuracy: 0.51 |         Val. Loss: 0.69 | Val. Accuracy: 0.51 |\n",
            "| Epoch: 02 | Train Loss: 0.69 | Train Accuracy: 0.56 |         Val. Loss: 0.70 | Val. Accuracy: 0.51 |\n",
            "| Epoch: 03 | Train Loss: 0.65 | Train Accuracy: 0.63 |         Val. Loss: 0.71 | Val. Accuracy: 0.51 |\n",
            "| Epoch: 04 | Train Loss: 0.57 | Train Accuracy: 0.71 |         Val. Loss: 0.76 | Val. Accuracy: 0.51 |\n",
            "| Epoch: 05 | Train Loss: 0.45 | Train Accuracy: 0.79 |         Val. Loss: 0.83 | Val. Accuracy: 0.51 |\n",
            "| Epoch: 06 | Train Loss: 0.32 | Train Accuracy: 0.87 |         Val. Loss: 0.92 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 07 | Train Loss: 0.22 | Train Accuracy: 0.91 |         Val. Loss: 1.07 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 08 | Train Loss: 0.15 | Train Accuracy: 0.95 |         Val. Loss: 1.18 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 09 | Train Loss: 0.11 | Train Accuracy: 0.97 |         Val. Loss: 1.33 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 10 | Train Loss: 0.08 | Train Accuracy: 0.98 |         Val. Loss: 1.40 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 11 | Train Loss: 0.06 | Train Accuracy: 0.98 |         Val. Loss: 1.54 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 12 | Train Loss: 0.05 | Train Accuracy: 0.99 |         Val. Loss: 1.61 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 13 | Train Loss: 0.04 | Train Accuracy: 0.99 |         Val. Loss: 1.68 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 14 | Train Loss: 0.03 | Train Accuracy: 0.99 |         Val. Loss: 1.80 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 15 | Train Loss: 0.02 | Train Accuracy: 0.99 |         Val. Loss: 1.87 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 16 | Train Loss: 0.02 | Train Accuracy: 0.99 |         Val. Loss: 1.94 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 17 | Train Loss: 0.02 | Train Accuracy: 1.00 |         Val. Loss: 1.99 | Val. Accuracy: 0.54 |\n",
            "| Epoch: 18 | Train Loss: 0.01 | Train Accuracy: 1.00 |         Val. Loss: 2.08 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 19 | Train Loss: 0.01 | Train Accuracy: 1.00 |         Val. Loss: 2.11 | Val. Accuracy: 0.53 |\n",
            "| Epoch: 20 | Train Loss: 0.01 | Train Accuracy: 1.00 |         Val. Loss: 2.02 | Val. Accuracy: 0.53 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "xkB9zYlQk-0K",
        "outputId": "f182dbd4-ec91-4cd3-aef1-223ff285be1f"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(log['epoch_acc'])\n",
        "plt.plot(log['valid_acc'])\n",
        "plt.legend(['training', 'validation'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accurracy')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accurracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3cN6zHzUHfz",
        "outputId": "ca83c536-e4b4-4a0d-e86a-68e3da9a8fa9"
      },
      "source": [
        "fake_labels = [1] * len(tokenized_test1)\n",
        "test_dataset = Task2Dataset_BiLSTM(vectorized_test1, vectorized_test2, fake_labels)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
        "\n",
        "\n",
        "def create_submission_file(test_loader):\n",
        "    # Get results\n",
        "    results  = np.array([])\n",
        "    for batch in test_loader:\n",
        "      X1, X2, target = batch\n",
        "      X1, X2, target = X1.to(device), X2.to(device), target.to(device)\n",
        "      model.batch_size = target.shape[0]\n",
        "      predictions = model(X1, X2).squeeze(1)\n",
        "      batch_results = np.argmax(predictions.detach().cpu().numpy(), axis=1)\n",
        "      results = np.concatenate((results, batch_results))\n",
        "\n",
        "    #Create data\n",
        "    ids = test_df['id']\n",
        "    results = results + 1\n",
        "    results = results.astype(int)\n",
        "\n",
        "    data = {'id': ids, \n",
        "            'pred': results}\n",
        "    df = pd.DataFrame(data, columns=['id', 'pred'])\n",
        "\n",
        "    #Export data to csv\n",
        "    compression_opts = dict(method='zip',archive_name='task-2-output-part2_best.csv') \n",
        "    df.to_csv('task-2-output-part2_best.zip', index=False, compression=compression_opts)\n",
        "    return\n",
        "\n",
        "create_submission_file(test_loader)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUlZmidx0Bln",
        "scrolled": true
      },
      "source": [
        "train_and_dev = train_df['edit1']\n",
        "\n",
        "training_data, dev_data, training_y, dev_y = train_test_split(train_df['edit1'], train_df['label'],\n",
        "                                                                        test_size=(1-train_proportion),\n",
        "                                                                        random_state=42)\n",
        "\n",
        "# We train a Tf-idf model\n",
        "count_vect = CountVectorizer(stop_words='english')\n",
        "train_counts = count_vect.fit_transform(training_data)\n",
        "transformer = TfidfTransformer().fit(train_counts)\n",
        "train_counts = transformer.transform(train_counts)\n",
        "naive_model = MultinomialNB().fit(train_counts, training_y)\n",
        "\n",
        "# Train predictions\n",
        "predicted_train = naive_model.predict(train_counts)\n",
        "\n",
        "# Calculate Tf-idf using train and dev, and validate on dev:\n",
        "test_and_test_counts = count_vect.transform(train_and_dev)\n",
        "transformer = TfidfTransformer().fit(test_and_test_counts)\n",
        "\n",
        "test_counts = count_vect.transform(dev_data)\n",
        "\n",
        "test_counts = transformer.transform(test_counts)\n",
        "\n",
        "# Dev predictions\n",
        "predicted = naive_model.predict(test_counts)\n",
        "\n",
        "# We run the evaluation:\n",
        "print(\"\\nTrain performance:\")\n",
        "\n",
        "sse, mse = model_performance(predicted_train, training_y, True)\n",
        "\n",
        "print(\"\\nDev performance:\")\n",
        "sse, mse = model_performance(predicted, dev_y, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYG40gkY0Bln"
      },
      "source": [
        "#### Baseline for task 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmzYO2i10Bln"
      },
      "source": [
        "# Baseline for the task\n",
        "pred_baseline = torch.zeros(len(dev_y)) + 1  # 1 is most common class\n",
        "print(\"\\nBaseline performance:\")\n",
        "sse, mse = model_performance(pred_baseline, torch.tensor(dev_y.values), True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XdB-5_I0Blo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKJ0AOd00Blo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}